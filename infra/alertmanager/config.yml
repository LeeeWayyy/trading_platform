# Alertmanager Configuration for Trading Platform
#
# Routes alerts from Prometheus to notification channels:
# - Critical alerts -> PagerDuty
# - Warning alerts -> Slack #alerts-ops
#
# Environment variables required:
# - SLACK_WEBHOOK_URL: Slack webhook for #alerts-ops
# - PAGERDUTY_SERVICE_KEY: PagerDuty integration key for platform-team

global:
  # How long to wait before sending a notification again
  resolve_timeout: 5m

  # Slack configuration
  slack_api_url: '${SLACK_WEBHOOK_URL}'

# Templates for notification formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Routing tree for alerts
route:
  # Default receiver for unmatched alerts
  receiver: 'slack-ops'

  # How long to wait before grouping matching alerts
  group_wait: 30s

  # How long to wait before sending another notification for a group
  group_interval: 5m

  # How long to wait before resending if still firing
  repeat_interval: 4h

  # Group alerts by these labels
  group_by: ['alertname', 'severity', 'team']

  # Child routes for severity-based routing
  routes:
    # Critical alerts -> PagerDuty + Slack
    - match:
        severity: critical
      receiver: 'pagerduty-platform'
      continue: true  # Also send to default (Slack)

    # Track 7 SLA alerts
    - match:
        sla: track7
      group_by: ['alertname']
      group_wait: 15s
      group_interval: 1m
      routes:
        - match:
            severity: critical
          receiver: 'pagerduty-platform'
        - match:
            severity: warning
          receiver: 'slack-ops'

# Notification receivers
receivers:
  # Slack channel for ops team
  - name: 'slack-ops'
    slack_configs:
      - channel: '#alerts-ops'
        send_resolved: true
        title: |-
          [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.alertname }}
        text: |-
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Runbook:* {{ .Annotations.runbook }}
          {{ end }}
        actions:
          - type: button
            text: 'Runbook'
            url: '{{ (index .Alerts 0).Annotations.runbook }}'
          - type: button
            text: 'Dashboard'
            url: 'http://localhost:3000/d/track7-slo/track7-slo'

  # PagerDuty for critical alerts
  - name: 'pagerduty-platform'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        send_resolved: true
        severity: '{{ .CommonLabels.severity }}'
        description: '{{ .CommonAnnotations.summary }}'
        details:
          firing: '{{ template "pagerduty.default.instances" .Alerts.Firing }}'
          resolved: '{{ template "pagerduty.default.instances" .Alerts.Resolved }}'
          num_firing: '{{ .Alerts.Firing | len }}'
          num_resolved: '{{ .Alerts.Resolved | len }}'

# Inhibition rules to suppress certain alerts
inhibit_rules:
  # If critical is firing, suppress warning for same alertname
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'team']

  # If CB verification failed, suppress staleness warning
  - source_match:
      alertname: 'CBVerificationFailed'
    target_match:
      alertname: 'CBStalenessHigh'
    equal: ['team']
