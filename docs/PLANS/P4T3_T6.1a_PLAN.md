# T6.1a Implementation Plan: Auth/RBAC Core

**Task:** T6.1a - Auth/RBAC Core
**Component:** T6.1a-Auth-RBAC-Core
**Status:** Plan Review (Revision 4)
**Created:** 2025-12-10
**Revised:** 2025-12-10 (v4 - Complete risk coverage)
**Author:** Claude Code

---

## Revision History

| Version | Reviewer | Status | Changes |
|---------|----------|--------|---------|
| v1 | Gemini | APPROVED_WITH_MINOR | Initial plan |
| v1 | Codex | NEEDS_REVISION | 2 HIGH, 3 MEDIUM issues |
| v2 | Gemini | APPROVED | Added step-up callback flow, strategy-scoped data access, aligned gates, added ops/monitoring, expanded tests |
| v2 | Codex | NEEDS_REVISION | 2 MEDIUM: missing cache/pagination in StrategyScopedDataAccess, step-up timeout not enforced |
| v3 | Gemini | APPROVED | Added Redis cache + pagination + streaming to StrategyScopedDataAccess, added step_up_requested_at validation |
| v3 | Codex | NEEDS_REVISION | 1 MEDIUM: risk coverage gaps, 1 LOW: backfill verification |
| v4 | - | Pending | Expanded risk table with all task-documented risks, added migration backfill verification SQL |

---

## Executive Summary

This plan implements Role-Based Access Control (RBAC) for the trading platform's web console. The implementation integrates with the existing OAuth2/PKCE authentication infrastructure (from P2) and adds:

1. **RBAC Permissions Layer** - viewer/operator/admin roles with default-deny
2. **Session Integration** - Extend SessionData with role/strategies/session_version/step_up_claims
3. **Per-Strategy Authorization** - Server-side strategy scoping via `StrategyScopedDataAccess`
4. **Comprehensive Audit Logging** - Enhanced audit_log schema with RBAC events + Prometheus metrics
5. **Session Invalidation** - Real-time privilege revocation on admin changes
6. **2FA Verification** - Auth0 step-up authentication with full callback flow + timeout handling
7. **Rate Limiting** - Redis-based sliding window rate limiter with health checks

---

## Pre-Implementation Analysis Summary

### Existing Infrastructure Analysis

| Component | File | Key Findings |
|-----------|------|--------------|
| OAuth2 Flow | `apps/web_console/auth/oauth2_flow.py` | 451 lines, PKCE + nonce, handle_callback returns userinfo |
| Session Store | `apps/web_console/auth/session_store.py` | AES-256-GCM encryption, `SessionData` model, Redis DB 1 |
| Session Manager | `apps/web_console/auth/session_manager.py` | IP/UA binding, `validate_session`, cookie management |
| Audit Log Table | `db/migrations/0004_add_audit_log.sql` | Existing table with user_id, action, details, reason, ip_address |
| Web Console App | `apps/web_console/app.py` | 871 lines, `render_manual_order_entry`, `audit_log()` function |
| Config | `apps/web_console/config.py` | DATABASE_URL, REDIS_HOST/PORT, AUTH_TYPE |

### Current SessionData Structure (to be extended)
```python
class SessionData(BaseModel):
    access_token: str
    refresh_token: str
    id_token: str
    user_id: str          # Auth0 user ID
    email: str
    created_at: datetime
    last_activity: datetime
    ip_address: str
    user_agent: str
    access_token_expires_at: datetime | None
    # NEW FIELDS TO ADD:
    # role: str
    # strategies: list[str]
    # session_version: int
    # step_up_claims: dict | None       # [NEW v2] For 2FA
    # step_up_requested_at: datetime | None  # [NEW v2] For timeout
    # pending_action: str | None        # [NEW v2] For post-callback redirect
```

### Integration Points Identified

1. **OAuth2 Login Success** (`oauth2_flow.py:handle_callback`) - Fetch role/strategies from DB
2. **Session Validation** (`session_manager.py:validate_session`) - Check session_version
3. **Step-Up Callback** (`step_up_callback.py`) - [NEW v2] Handle 2FA return from Auth0
4. **Protected Actions** (`app.py`) - Manual orders, kill switch, audit log viewer
5. **Audit Logging** (`app.py:audit_log`) - Extend to log RBAC events

---

## Implementation Components

### Component 1: Database Migrations

**Files to Create:**
- `db/migrations/0005_update_audit_log_schema.sql` - ALTER TABLE for audit_log
- `db/migrations/0006_create_rbac_tables.sql` - user_roles, strategies, user_strategy_access

**0005 Migration - Audit Log Schema Update:**
```sql
-- Extend existing audit_log table for RBAC events
ALTER TABLE audit_log
ADD COLUMN IF NOT EXISTS event_type VARCHAR(20),       -- access, action, auth, admin
ADD COLUMN IF NOT EXISTS resource_type VARCHAR(50),   -- order, position, strategy, user
ADD COLUMN IF NOT EXISTS resource_id VARCHAR(255),    -- Specific resource identifier
ADD COLUMN IF NOT EXISTS outcome VARCHAR(20),         -- success, denied, failed
ADD COLUMN IF NOT EXISTS amr_method VARCHAR(20);      -- MFA method: otp, sms, webauthn

-- Backfill existing rows
UPDATE audit_log SET event_type = 'action' WHERE event_type IS NULL;
UPDATE audit_log SET resource_type = 'system' WHERE resource_type IS NULL;
UPDATE audit_log SET outcome = 'success' WHERE outcome IS NULL;

-- Add NOT NULL constraints after backfill
ALTER TABLE audit_log ALTER COLUMN event_type SET NOT NULL;
ALTER TABLE audit_log ALTER COLUMN resource_type SET NOT NULL;
ALTER TABLE audit_log ALTER COLUMN outcome SET NOT NULL;

-- New indexes
CREATE INDEX IF NOT EXISTS idx_audit_event_type ON audit_log (event_type, timestamp DESC);
CREATE INDEX IF NOT EXISTS idx_audit_outcome ON audit_log (outcome) WHERE outcome != 'success';
```

**0006 Migration - RBAC Tables:**
```sql
CREATE TABLE IF NOT EXISTS user_roles (
    user_id VARCHAR(255) PRIMARY KEY,
    role VARCHAR(20) NOT NULL DEFAULT 'viewer',
    session_version INTEGER NOT NULL DEFAULT 1,
    updated_by VARCHAR(255),
    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    CONSTRAINT valid_role CHECK (role IN ('viewer', 'operator', 'admin'))
);

CREATE TABLE IF NOT EXISTS strategies (
    strategy_id VARCHAR(50) PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE TABLE IF NOT EXISTS user_strategy_access (
    user_id VARCHAR(255) NOT NULL,
    strategy_id VARCHAR(50) NOT NULL,
    granted_by VARCHAR(255) NOT NULL,
    granted_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    PRIMARY KEY (user_id, strategy_id),
    CONSTRAINT fk_user FOREIGN KEY (user_id) REFERENCES user_roles(user_id) ON DELETE CASCADE,
    CONSTRAINT fk_strategy FOREIGN KEY (strategy_id) REFERENCES strategies(strategy_id) ON DELETE CASCADE
);

CREATE INDEX idx_user_strategy_user ON user_strategy_access (user_id);
CREATE INDEX idx_user_strategy_strategy ON user_strategy_access (strategy_id);
```

---

### Component 2: Permissions Module

**File:** `apps/web_console/auth/permissions.py`

**Key Classes/Functions:**
```python
class Role(str, Enum):
    VIEWER = "viewer"      # Read-only access to assigned strategies
    OPERATOR = "operator"  # Can execute trades, cancel orders
    ADMIN = "admin"        # Full access to all strategies and settings

class Permission(str, Enum):
    VIEW_POSITIONS = "view_positions"
    VIEW_PNL = "view_pnl"
    VIEW_TRADES = "view_trades"
    CANCEL_ORDER = "cancel_order"
    CLOSE_POSITION = "close_position"
    FLATTEN_ALL = "flatten_all"
    MANAGE_USERS = "manage_users"
    VIEW_ALL_STRATEGIES = "view_all_strategies"
    EXPORT_DATA = "export_data"

ROLE_PERMISSIONS: dict[Role, set[Permission]] = {
    Role.VIEWER: {VIEW_POSITIONS, VIEW_PNL, VIEW_TRADES, EXPORT_DATA},
    Role.OPERATOR: {VIEW_POSITIONS, VIEW_PNL, VIEW_TRADES, CANCEL_ORDER, CLOSE_POSITION, EXPORT_DATA},
    Role.ADMIN: set(Permission),  # All permissions
}

def has_permission(user: dict, permission: Permission) -> bool
def require_permission(permission: Permission) -> Callable  # Decorator
def get_authorized_strategies(user: dict) -> list[str]
def validate_session_sync(...) -> dict | None  # Sync wrapper for Streamlit
```

**Key Design Decisions:**
1. **Default-deny on unknown roles** - `_get_role_safe()` returns None for unknown, denied by `has_permission()`
2. **Sync wrappers** - `validate_session_sync()` uses ThreadPoolExecutor + fresh Redis/DB connections
3. **Logging** - Both granted and denied access logged to audit trail

---

### Component 3: Audit Logger Enhancement

**File:** `apps/web_console/auth/audit_log.py`

**Key Features:**
```python
class AuditLogger:
    async def log_access(user_id, resource_type, resource_id, outcome, details)
    async def log_action(user_id, action, resource_type, resource_id, outcome, details)
    async def log_auth_event(user_id, action, outcome, details)
    async def log_admin_change(admin_user_id, action, target_user_id, details)
    async def log_export(user_id, export_type, resource_type, row_count)
    async def cleanup_old_events() -> int  # Returns count deleted
```

**Retention Policy:**
- Default: 90 days (configurable via `AUDIT_RETENTION_DAYS`)
- Cleanup: Daily scheduled task at 02:00 UTC
- PII minimization: Log user_id, not email, in details

**File:** `apps/web_console/tasks/audit_cleanup.py`
- Scheduled task for daily cleanup
- **[NEW v2] Emits Prometheus metrics:**
  - `audit_cleanup_deleted_count` - Counter of deleted rows
  - `audit_cleanup_last_run_timestamp` - Gauge for monitoring
  - `audit_cleanup_duration_seconds` - Histogram

**[NEW v2] Ops/Monitoring Requirements:**
- **Prometheus Alert:** `audit_cleanup_last_run_timestamp > 25h` triggers page
- **Scheduler Deployment:** APScheduler worker configured in `infra/docker-compose.yaml`
- **Ops Ticket:** Created before T6.1a merge to deploy scheduler at 02:00 UTC

---

### Component 4: Session Invalidation

**File:** `apps/web_console/auth/session_invalidation.py`

**Key Functions:**
```python
async def invalidate_user_sessions(user_id, db_pool, audit_logger, admin_user_id) -> int
    # Increments session_version in user_roles table
    # Returns new session_version

async def validate_session_version(user_id, session_version, db_pool) -> bool
    # Returns False if session_version doesn't match DB
    # Returns False if user has no user_roles row (deprovisioned)
```

**Integration:**
- Called when admin changes role/strategy access
- `validate_session()` checks session_version on EVERY request
- Forces re-login on mismatch (user picks up new permissions)

---

### Component 5: MFA Verification + Step-Up Callback [ENHANCED v2]

**[FIXED - per Codex HIGH: Plan omits step-up callback handler and session fields]**

**Files:**
- `apps/web_console/auth/mfa_verification.py` - Core verification logic
- `apps/web_console/auth/step_up_callback.py` - **[NEW v2]** Callback handler

**MFA Verification Key Functions:**
```python
def verify_step_up_auth(id_token_claims: dict) -> tuple[bool, str | None]
    # Checks auth_time < 60 seconds
    # Checks amr claim contains MFA method
    # Returns (success, error_reason)

def get_amr_method(id_token_claims: dict) -> str | None
    # Extracts MFA method for audit logging

async def require_2fa_for_action(session_data, action, audit_logger) -> tuple[bool, str | None]
    # Returns (allowed, error_message)
    # [ENHANCED v2] Checks step_up_claims in session, validates timeout
```

**[ENHANCED v3] Step-Up Callback Handler:**

**[FIXED v3 - per Codex MEDIUM: Timeout enforcement using step_up_requested_at]**

```python
# apps/web_console/auth/step_up_callback.py
STEP_UP_CALLBACK_TIMEOUT_SECONDS = 300  # 5 minutes

async def handle_step_up_callback(
    code: str,
    state: str,
    session_store: Any,
    session_id: str,
    audit_logger: Any,
) -> dict:
    """Handle Auth0 callback after step-up authentication.

    [ENHANCED v3] Now validates step_up_requested_at for timeout enforcement.

    Flow:
    1. Validate state matches session (CSRF protection)
    2. [NEW v3] Check step_up_requested_at within 5-minute window
    3. Exchange code for tokens
    4. Verify id_token.amr contains MFA method
    5. Verify id_token.auth_time is recent (< 60s)
    6. Store step_up_claims in session
    7. Clear step_up_requested_at and pending_action
    8. Redirect back to pending_action

    Failure Modes:
    - [NEW v3] Timeout (5 min): Clear pending_action, step_up_claims, return error
    - User cancels: Log denied, redirect to dashboard
    - MFA not in amr: Reject, log, prompt re-enroll
    - State mismatch: Security error, force logout
    """
    # Get current session data
    session_data = await session_store.get(session_id)
    if not session_data:
        raise SecurityError("Session not found")

    # [NEW v3] CRITICAL: Validate callback arrived within timeout window
    step_up_requested_at = session_data.get("step_up_requested_at")
    if step_up_requested_at:
        elapsed = (datetime.now(UTC) - step_up_requested_at).total_seconds()
        if elapsed > STEP_UP_CALLBACK_TIMEOUT_SECONDS:
            # Timeout - clear all step-up state
            await session_store.clear_step_up_state(session_id)
            await audit_logger.log_auth_event(
                user_id=session_data.get("user_id"),
                action="step_up_timeout",
                outcome="denied",
                details={"elapsed_seconds": elapsed, "max_seconds": STEP_UP_CALLBACK_TIMEOUT_SECONDS},
            )
            return {
                "error": "step_up_timeout",
                "message": "Step-up authentication timed out. Please try again.",
                "redirect_to": "/dashboard",
            }

    # Validate state (CSRF protection)
    if not validate_state(state, session_id):
        await session_store.clear_step_up_state(session_id)
        raise SecurityError("Invalid authentication state")

    # Exchange code for tokens
    tokens = await exchange_code(code)
    id_token_claims = tokens.get("id_token_claims", {})

    # Verify MFA was performed
    valid, error = verify_step_up_auth(id_token_claims)
    if not valid:
        await session_store.clear_step_up_state(session_id)
        await audit_logger.log_auth_event(
            user_id=id_token_claims.get("sub"),
            action="step_up_callback_failed",
            outcome="denied",
            details={"error": error},
        )
        return {
            "error": error,
            "message": _get_error_message(error),
            "redirect_to": "/dashboard",
        }

    # Success - store claims and redirect
    pending_action = session_data.get("pending_action", "/dashboard")
    await session_store.update_step_up_claims(
        session_id=session_id,
        step_up_claims=id_token_claims,
        amr_method=get_amr_method(id_token_claims),
    )
    # [NEW v3] Clear request timestamp after successful callback
    await session_store.clear_step_up_request_timestamp(session_id)

    await audit_logger.log_auth_event(
        user_id=id_token_claims.get("sub"),
        action="step_up_success",
        outcome="success",
        details={"amr_method": get_amr_method(id_token_claims)},
    )

    return {"redirect_to": pending_action}

async def clear_step_up_state(session_id: str) -> None:
    """Clear all step-up related session fields.

    [NEW v3] Called on timeout, error, or state mismatch to prevent replay.
    """
    # Clears: step_up_claims, step_up_requested_at, pending_action
```

**[NEW v2] Session Store Fields for Step-Up:**
```python
class SessionData(BaseModel):
    # ... existing fields ...
    step_up_claims: dict | None = None       # ID token claims from step-up
    step_up_requested_at: datetime | None = None  # For timeout enforcement
    pending_action: str | None = None        # URL to redirect after step-up

async def update_step_up_claims(session_id, step_up_claims, amr_method) -> None:
    """Update session with step-up claims after successful MFA."""
```

**Step-Up Flow (Complete):**
```
1. User clicks "Flatten All" (requires 2FA)
   └─► Check session.step_up_claims.auth_time < 60s
       └─► If expired/missing:
           ├─ Store pending_action="/manual_controls?action=flatten_all" in session
           ├─ Store step_up_requested_at=now() in session
           ├─ Redirect to Auth0 with prompt=login&max_age=0
           └─ Set timeout: 5 minutes for callback

2. Auth0 Step-Up Callback (/auth/step-up-callback)
   └─► handle_step_up_callback():
       ├─ Validate state matches session
       ├─ Verify id_token.amr contains MFA method
       ├─ Verify id_token.auth_time is recent (< 60s)
       ├─ Store step_up_claims in session (TTL: 60s)
       └─ Redirect back to pending_action

3. Failure Modes
   ├─ Timeout (5 min): Clear pending_action, show error
   ├─ User cancels: Log denied, redirect to dashboard
   ├─ MFA not in amr: Reject, log, prompt re-enroll
   └─ State mismatch: Security error, force logout
```

---

### Component 6: Rate Limiter

**File:** `apps/web_console/auth/rate_limiter.py`

**Key Features:**
```python
class RateLimiter:
    def check_rate_limit(user_id, action, max_requests, window_seconds) -> tuple[bool, int]
    def _handle_redis_failure(user_id, action, error) -> tuple[bool, int]  # Fallback
    def health_check() -> bool

def get_rate_limiter() -> RateLimiter  # Global singleton with connection pool
def check_rate_limit(user_id, action, max_requests, window_seconds) -> bool  # Convenience
def rate_limiter_health_check() -> dict  # [NEW v2] For /health endpoint
```

**Redis Configuration:**
- Uses separate Redis DB (db=2) to avoid contention with sessions (db=1)
- Connection pool: max 20 connections, 1s socket timeout, 2s connect timeout
- Fallback mode: "allow" on Redis failure (configurable via `RATE_LIMITER_FALLBACK_MODE`)
- Sliding window using Redis sorted sets (ZADD + ZREMRANGEBYSCORE)

**[NEW v2] Prometheus Metrics:**
- `rate_limit_checks_total{action,result}` - Counter
- `rate_limit_redis_errors_total` - Counter for fallback triggers
- Health check integrated with `/health` endpoint

---

### Component 7: Server-Side Strategy Scoping [ENHANCED v3]

**[FIXED v2 - per Codex HIGH: Server-side strategy scoping not planned]**
**[FIXED v3 - per Codex MEDIUM: Missing cache/pagination/streaming controls]**

**File:** `apps/web_console/data/strategy_scoped_queries.py`

**Key Class:**
```python
class StrategyScopedDataAccess:
    """Data access layer with mandatory strategy scoping.

    ALL dashboard data queries MUST go through this class to ensure
    users only see data for their authorized strategies.

    Features:
    - Server-side strategy filtering (mandatory)
    - Redis caching with 5-minute TTL (keyed by user_id + strategy_set_hash)
    - Pagination with enforced limits (default 100, max 1000)
    - Streaming cursors for exports (avoids OOM)
    """

    # [NEW v3] Configuration
    DEFAULT_LIMIT = 100
    MAX_LIMIT = 1000
    CACHE_TTL_SECONDS = 300  # 5 minutes

    def __init__(self, db_pool: Any, redis_client: Any, user: dict):
        self.db_pool = db_pool
        self.redis = redis_client  # [NEW v3] For caching
        self.user = user
        self.user_id = user.get("sub")
        self.authorized_strategies = get_authorized_strategies(user)
        self._cache_key_prefix = self._build_cache_key_prefix()

    def _build_cache_key_prefix(self) -> str:
        """Build cache key prefix from user_id + strategy set hash.

        [NEW v3] Ensures cache isolation per user AND strategy assignment.
        Cache invalidates when session_version changes (re-login required).
        """
        import hashlib
        strategy_hash = hashlib.md5(
            ",".join(sorted(self.authorized_strategies)).encode()
        ).hexdigest()[:8]
        return f"scoped_data:{self.user_id}:{strategy_hash}"

    async def get_positions(
        self,
        limit: int = DEFAULT_LIMIT,
        offset: int = 0,
        use_cache: bool = True,
        **filters
    ) -> list[dict]:
        """Get positions filtered by authorized strategies.

        [ENHANCED v3] With caching and pagination.
        """
        limit = min(limit, self.MAX_LIMIT)  # Enforce cap
        cache_key = f"{self._cache_key_prefix}:positions:{offset}:{limit}"

        if use_cache:
            cached = await self._get_cached(cache_key)
            if cached is not None:
                return cached

        strategies = self._get_strategy_filter()
        async with self.db_pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT * FROM positions
                WHERE strategy_id = ANY($1)
                ORDER BY updated_at DESC
                LIMIT $2 OFFSET $3
                """,
                strategies, limit, offset,
            )
            result = [dict(row) for row in rows]

        await self._set_cached(cache_key, result)
        return result

    async def get_orders(self, limit: int = DEFAULT_LIMIT, offset: int = 0, **filters) -> list[dict]
    async def get_pnl_summary(self, date_from, date_to, limit: int = DEFAULT_LIMIT, offset: int = 0) -> list[dict]
    async def get_trades(self, limit: int = DEFAULT_LIMIT, offset: int = 0, **filters) -> list[dict]

    async def stream_trades_for_export(self, **filters) -> AsyncGenerator[dict, None]:
        """Stream trades for CSV/Excel export using server-side cursor.

        [NEW v3] Prevents OOM on large exports by streaming rows.
        Uses PostgreSQL server-side cursor (DECLARE/FETCH).
        """
        strategies = self._get_strategy_filter()
        async with self.db_pool.acquire() as conn:
            async with conn.transaction():
                async for row in conn.cursor(
                    """
                    SELECT * FROM trades
                    WHERE strategy_id = ANY($1)
                    ORDER BY executed_at DESC
                    """,
                    strategies,
                ):
                    yield dict(row)

    def _get_strategy_filter(self) -> list[str]:
        """Raises PermissionError if user has no strategy access."""
        if not self.authorized_strategies:
            raise PermissionError("No strategy access")
        return self.authorized_strategies

    async def _get_cached(self, key: str) -> list[dict] | None:
        """Get from Redis cache."""
        import json
        data = await self.redis.get(key)
        if data:
            return json.loads(data)
        return None

    async def _set_cached(self, key: str, data: list[dict]) -> None:
        """Set in Redis cache with TTL."""
        import json
        await self.redis.setex(key, self.CACHE_TTL_SECONDS, json.dumps(data))

def get_scoped_data_access(db_pool, redis_client, user) -> StrategyScopedDataAccess:
    """Factory function for strategy-scoped data access."""
    return StrategyScopedDataAccess(db_pool, redis_client, user)
```

**[NEW v3] Cache Design:**
- **Redis DB:** Use db=1 (same as sessions) or db=3 (dedicated cache)
- **Key Format:** `scoped_data:{user_id}:{strategy_hash}:{resource}:{offset}:{limit}`
- **TTL:** 5 minutes (matches task requirement)
- **Invalidation:** Cache keys include strategy_hash, so cache auto-invalidates when:
  - User re-logs in after role/strategy change (new session, new strategy_hash)
  - TTL expires (5 minutes)

**[NEW v3] Pagination Enforcement:**
- Default limit: 100 rows
- Maximum limit: 1000 rows (defensive cap)
- All list queries accept `limit` and `offset` parameters
- UI components must paginate large result sets

**[NEW v3] Streaming Export:**
- `stream_trades_for_export()` uses PostgreSQL server-side cursor
- Yields rows one-at-a-time to avoid loading entire result set in memory
- Used by CSV/Excel export functions in T6.5 (Trade Journal)

**Enforcement Points:**
- `permissions.py::get_authorized_strategies()` provides the interface
- `StrategyScopedDataAccess` enforces filtering on ALL data queries
- Admin role uses `VIEW_ALL_STRATEGIES` permission → queries all strategy IDs
- Empty strategy list → `PermissionError` (fail-closed)

---

### Component 8: Session Store Update

**File:** `apps/web_console/auth/session_store.py` (UPDATE)

**Changes:**
```python
class SessionData(BaseModel):
    # ... existing fields ...
    # NEW fields:
    role: str = "viewer"                      # viewer, operator, admin
    strategies: list[str] = []                # Authorized strategy IDs
    session_version: int = 1                  # For invalidation on role change
    # [NEW v2] Step-up fields:
    step_up_claims: dict | None = None        # ID token claims from MFA
    step_up_requested_at: datetime | None = None  # Timeout enforcement
    pending_action: str | None = None         # Post-callback redirect URL
```

---

### Component 9: OAuth2 Flow Update

**File:** `apps/web_console/auth/oauth2_flow.py` (UPDATE)

**Changes to `handle_callback()`:**
```python
async def handle_callback(code, state, db_pool, audit_logger, **kwargs):
    # ... existing token exchange ...

    # NEW: Fetch role and session_version from database
    role_data = await _fetch_user_role_data(user_id, db_pool)
    if role_data is None:
        # Deny login if user not provisioned
        await audit_logger.log_auth_event(user_id, "login", "denied", {"reason": "user_not_provisioned"})
        raise AuthorizationError("User not provisioned. Contact administrator.")

    strategies = await _fetch_user_strategies(user_id, db_pool)

    session = SessionData(
        # ... existing fields ...
        role=role_data["role"],
        strategies=strategies,
        session_version=role_data["session_version"],
    )
```

---

### Component 10: Admin Bootstrap CLI

**File:** `scripts/manage_roles.py`

**Commands:**
```bash
# Bootstrap initial admin
python scripts/manage_roles.py bootstrap-admin

# Set user role
python scripts/manage_roles.py set-role --user-id auth0|123 --role admin --by admin@example.com

# Grant strategy access
python scripts/manage_roles.py grant-strategy --user-id auth0|123 --strategy alpha_baseline --by admin@example.com

# List users
python scripts/manage_roles.py list-users
```

---

### Component 11: ADR Document

**File:** `docs/ADRs/ADR-024-analytics-security.md`

**Decisions to Document:**
1. **Role Sourcing:** DB-based vs Auth0 custom claims → Decision: DB (simpler, auditable)
2. **Session Invalidation:** Immediate vs polling → Decision: session_version per-request
3. **2FA Mechanism:** Auth0 step-up vs internal TOTP → Decision: Auth0 step-up
4. **Rate Limiter Fallback:** Fail-open vs fail-closed → Decision: Fail-open (configurable)
5. **Strategy Scoping:** Client vs server-side → Decision: Server-side only

---

## Implementation Order [ALIGNED v2]

**[FIXED - per Codex MEDIUM: Gate sequence drift from task document]**

Per task document Gate requirements (aligned with P4T3_TASK.md):

### Gate 0: DB Migrations
- Create ADR-024 (document decisions first)
- Create 0005_update_audit_log_schema.sql
- Create 0006_create_rbac_tables.sql
- Verify migrations in staging (dry-run with backfill)

### Gate 1: RBAC Core + Session Version
- Implement permissions.py (with `get_authorized_strategies`)
- Implement audit_log.py (with Prometheus metrics)
- Implement session_invalidation.py
- Implement strategy_scoped_queries.py **[NEW v2]**
- Update session_store.py (role/strategies/session_version + step_up fields)
- Update session_manager.py (session_version validation)
- Update oauth2_flow.py (fetch role on login)
- Create manage_roles.py CLI
- **Feature flag:** `ENABLE_RBAC=true`
- Smoke test auth flow before proceeding

### Gate 2: Rate Limiter
- Implement rate_limiter.py
- Configure Redis DB index (db=2)
- Performance testing (100 concurrent checks < 2s)
- Integrate with /health endpoint

### Gate 3: Manual Controls Backend **[ALIGNED v2]**
- **Note:** Per task, T6.6 (Manual Trade Controls) ships with execution_gateway backend in same PR
- T6.1a provides: 2FA verification, rate limiting, permissions
- Step-up callback handler (`step_up_callback.py`) - **[NEW v2]**
- MFA verification (`mfa_verification.py`)
- T6.6 will implement actual manual control endpoints using T6.1a components

### Gate 4: Dashboards (T6.2-T6.5)
- Enabled incrementally behind per-page feature flags
- Uses `StrategyScopedDataAccess` for all data queries

---

## Files to Create (21 files) [EXPANDED v2]

**[FIXED - per Gemini/Codex: Missing files added]**

| File | Type | LOC Est. |
|------|------|----------|
| `docs/ADRs/ADR-024-analytics-security.md` | ADR | 150 |
| `db/migrations/0005_update_audit_log_schema.sql` | SQL | 30 |
| `db/migrations/0006_create_rbac_tables.sql` | SQL | 50 |
| `apps/web_console/auth/permissions.py` | Python | 200 |
| `apps/web_console/auth/audit_log.py` | Python | 150 |
| `apps/web_console/auth/session_invalidation.py` | Python | 80 |
| `apps/web_console/auth/mfa_verification.py` | Python | 120 |
| `apps/web_console/auth/step_up_callback.py` | Python | 100 | **[NEW v2]**
| `apps/web_console/auth/rate_limiter.py` | Python | 180 |
| `apps/web_console/data/strategy_scoped_queries.py` | Python | 120 | **[NEW v2]**
| `apps/web_console/tasks/audit_cleanup.py` | Python | 70 | **[EXPANDED v2]**
| `scripts/manage_roles.py` | Python | 150 |
| `tests/apps/web_console/auth/test_permissions.py` | Test | 250 | **[EXPANDED v2]**
| `tests/apps/web_console/auth/test_audit_log.py` | Test | 100 |
| `tests/apps/web_console/auth/test_session_invalidation.py` | Test | 80 |
| `tests/apps/web_console/auth/test_mfa_verification.py` | Test | 150 | **[EXPANDED v2]**
| `tests/apps/web_console/auth/test_rate_limiter.py` | Test | 150 |
| `tests/apps/web_console/perf/test_rate_limiter_load.py` | Test | 100 | **[NEW v2]**
| `tests/apps/web_console/perf/test_auth_sync_wrappers.py` | Test | 80 | **[NEW v2]**
| `tests/apps/web_console/security/test_strategy_scoping.py` | Test | 120 | **[NEW v2]**
| `tests/apps/web_console/e2e/test_audit_retention.py` | Test | 80 | **[NEW v2]**

**Total: ~2,510 LOC**

## Files to Update (3 files)

| File | Changes |
|------|---------|
| `apps/web_console/auth/session_store.py` | Add role/strategies/session_version/step_up_claims to SessionData |
| `apps/web_console/auth/session_manager.py` | Add session_version validation in validate_session |
| `apps/web_console/auth/oauth2_flow.py` | Fetch role/strategies on login, accept db_pool param |

---

## Testing Strategy [EXPANDED v2]

**[FIXED - per Codex MEDIUM: Testing section missing critical security cases]**

### Unit Tests
- RBAC permission checks (including unknown role handling)
- Audit log serialization and persistence
- Rate limiter sliding window logic
- 2FA amr claim validation
- **[NEW v2] Denied-path tests:**
  - Unknown role → default-deny
  - Stale session_version → force re-login
  - Empty strategy list → PermissionError

### Integration Tests
- Session + RBAC integration (oauth2_flow → session_store → permissions)
- Dashboard data fetching with strategy filtering
- Audit log persistence and query
- Rate limiter Redis integration
- **[ENHANCED v3] Step-up callback flow:**
  - Success path with amr validation
  - **[NEW v3] Timeout validation using step_up_requested_at**
  - **[NEW v3] Delayed/replayed callback rejection (>5 min)**
  - **[NEW v3] clear_step_up_state on timeout/error**
  - User cancel → dashboard redirect
  - State mismatch → security error

### Security Tests (`tests/apps/web_console/security/`)
- **[ENHANCED v3] Strategy leakage prevention:**
  - Viewer only sees assigned strategies
  - Admin sees all strategies
  - No strategy access → PermissionError
  - All query methods apply filter
  - **[NEW v3] Cache isolation per user+strategy_hash**
  - **[NEW v3] Pagination caps enforced (max 1000)**
- **[NEW v2] Rate limiter fallback:**
  - Fail-open behavior on Redis failure
  - Configurable fail-closed mode
- **[NEW v2] Audit PII minimization:**
  - user_id logged, not email
  - No sensitive data in details JSON
- **[NEW v3] Step-up replay prevention:**
  - Callback >5 min after request → rejected
  - step_up_claims cleared on timeout
  - Replayed/delayed callback cannot re-arm step_up

### Load/Performance Tests (`tests/apps/web_console/perf/`)
- **[NEW v2] Rate limiter under load:**
  - 100 concurrent checks < 2s
  - 50 users x 10 rapid requests
  - Health check latency < 100ms
- **[NEW v2] Auth sync wrappers:**
  - 20 concurrent session validations < 5s
  - No connection leaks (verify pool size)

### E2E Tests
- Full authentication flow with role fetching
- **[NEW v2] Audit retention:**
  - Events persisted to database
  - Old events (>90 days) deleted by cleanup
  - amr_method recorded for 2FA events

---

## Ops/Monitoring Requirements [NEW v2]

**[FIXED - per Codex MEDIUM: Missing ops wiring]**

### Prometheus Metrics
```yaml
# Audit cleanup metrics
audit_cleanup_deleted_count       # Counter - rows deleted per run
audit_cleanup_last_run_timestamp  # Gauge - for staleness alert
audit_cleanup_duration_seconds    # Histogram - cleanup performance

# Rate limiter metrics
rate_limit_checks_total{action,result}  # Counter - allowed/denied
rate_limit_redis_errors_total           # Counter - fallback triggers
```

### Prometheus Alerts
```yaml
# Alert if audit cleanup hasn't run in 25 hours
- alert: AuditCleanupStale
  expr: time() - audit_cleanup_last_run_timestamp > 90000
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "Audit cleanup hasn't run in >25 hours"

# Alert on rate limiter Redis failures
- alert: RateLimiterRedisErrors
  expr: rate(rate_limit_redis_errors_total[5m]) > 0
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "Rate limiter falling back due to Redis errors"
```

### Scheduler Deployment
- **Action Required:** Create ops ticket before T6.1a merge
- **Configuration:** APScheduler in `infra/docker-compose.yaml`
- **Schedule:** `audit_cleanup.py` at 02:00 UTC daily
- **Verification:** `SELECT MAX(timestamp) FROM audit_log WHERE action = 'cleanup_completed';`

---

## Risk Mitigation [EXPANDED v3]

**[FIXED v3 - per Codex MEDIUM: Add all task-documented risks]**

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| **Unauthorized access** | Medium | Critical | RBAC + per-request session_version validation + audit logging |
| **Accidental flatten** | Low | Critical | 2FA step-up auth (amr claim) + rate limiting (1 per 5min) + reason field (min 20 chars) |
| **Performance/SLO degradation** | Medium | Medium | Redis caching (5min TTL), pagination (100 default, 1000 max), streaming cursors for exports, dashboard load <2s SLO |
| **Session hijacking** | Low | High | Existing IP/UA binding + session_version per-request check + forced re-login on mismatch |
| **Unknown role crashes** | Low | Medium | Default-deny pattern, `_get_role_safe()` returns None, never ValueError |
| **Stale elevated access** | Low | High | session_version increment on role/strategy change → immediate invalidation |
| **Rate limit bypass** | Low | Medium | Server-side Redis rate limiter in execution_gateway, not just UI |
| **Strategy data leakage** | Medium | Critical | Server-side StrategyScopedDataAccess, cache keyed by user+strategy_hash, regression tests |
| **CSRF on admin actions** | Low | Medium | Session state nonce (CSRF token) + double confirmation for bulk ops |
| **Redis contention (sessions vs rate limiter)** | Medium | High | Separate Redis DB (db=1 sessions, db=2 rate limiter) + connection pool limits (max 20) + health checks |
| **Migration backfill failure** | Low | High | Dry-run in staging + pg_dump checkpoint + **[NEW v3] verify rowcount after backfill** |
| **Streamlit sync wrapper blocking** | Medium | Medium | Per-request fresh pool + ThreadPoolExecutor with 5s timeout + load tests verify no leaks |
| **Scheduler not deployed** | Medium | Medium | Ops ticket created before merge + Prometheus alert on audit_cleanup_last_run > 25h |
| **Step-up timeout bypass** | Low | High | Validate step_up_requested_at within 5min window + clear_step_up_state on timeout/error |

**[NEW v3] Migration Backfill Verification:**
```sql
-- Run after 0005 migration to verify backfill success
SELECT
    COUNT(*) AS total_rows,
    COUNT(*) FILTER (WHERE event_type IS NOT NULL) AS backfilled_event_type,
    COUNT(*) FILTER (WHERE resource_type IS NOT NULL) AS backfilled_resource_type,
    COUNT(*) FILTER (WHERE outcome IS NOT NULL) AS backfilled_outcome
FROM audit_log;

-- Expected: all counts should be equal (100% backfill)
-- Alert if backfilled_* < total_rows
```

---

## Acceptance Criteria

- [ ] RBAC with viewer/operator/admin roles
- [ ] Default-deny on unknown roles (no ValueError crash)
- [ ] @require_permission decorator with sync wrappers
- [ ] Session invalidation on role/strategy changes
- [ ] Audit logging for ALL events (access, denied, auth, admin, export)
- [ ] Per-strategy authorization enforced server-side via `StrategyScopedDataAccess`
- [ ] Session includes role, strategies, session_version, step_up_claims
- [ ] 2FA validation via amr claim with full callback flow
- [ ] Step-up timeout handling (5 min)
- [ ] Admin bootstrap CLI
- [ ] Rate limiter with Prometheus metrics
- [ ] Audit cleanup with Prometheus metrics + alert
- [ ] >90% test coverage
- [ ] Security regression tests pass (no strategy leakage)
- [ ] Load tests pass (rate limiter, sync wrappers)
- [ ] CI passes (`make ci-local`)
- [ ] Independent code review approval (Gemini + Codex)

---

## Questions/Clarifications

**Clarification on `StrategyScopedDataAccess` scope:**
- Per task document, `StrategyScopedDataAccess` is listed under T6.6 (Manual Trade Controls)
- However, `get_authorized_strategies()` in T6.1a needs server-side enforcement
- **Decision:** T6.1a implements both `permissions.py::get_authorized_strategies()` AND `strategy_scoped_queries.py::StrategyScopedDataAccess` to ensure complete server-side enforcement
- T6.6 will use this data access layer for manual controls

---

**Plan Ready for Review (v4)**
