# P4T4-T5.3: Backtest Web UI

**Parent Task:** [P4T4_TASK.md](./P4T4_TASK.md)
**Task ID:** P4T4-T5.3

### T5.3: Backtest Web UI

**Effort:** 4-5 days | **PR:** `feat(p4): backtest web ui`
**Status:** ‚è≥ Pending
**Dependencies:** T5.1, T5.2, T6.1 (Auth)

**Auth Dependency Strategy:**
- **If T6.1 complete:** Use production OAuth2 auth via `@requires_auth`
- **If T6.1 pending:** Use dev-mode auth stub with `BACKTEST_DEV_AUTH=true` env var
- **Dev-mode stub:** Returns fixed user `{"username": "dev_user", "role": "operator"}`
- **CI enforcement:** Test `test_no_dev_auth_in_prod` fails if `BACKTEST_DEV_AUTH` is set in production config

**Auth Stub Rollback Path (when T6.1 ships):**
1. Remove `BACKTEST_DEV_AUTH=true` from all non-local env files (`.env.prod`, `docker-compose.prod.yml`, Helm/infra values if present)
2. Replace `@backtest_requires_auth` with standard `@requires_auth` **and update imports explicitly:** replace `from apps.web_console.auth.backtest_auth import backtest_requires_auth` with `from apps.web_console.auth.streamlit_helpers import requires_auth` in both `apps/web_console/pages/backtest.py` and `apps/web_console/app.py` (no wrapper re-exports)
3. Delete `apps/web_console/auth/backtest_auth.py`
4. Update `test_auth_governance.py` to verify no `BACKTEST_DEV_AUTH` references remain
5. Add a CI governance check that fails if `backtest_requires_auth` is referenced after T6.1 ships (guards manual import regressions)
6. CI will auto-fail if any stub references persist
7. If Helm/Kubernetes deployment is used (e.g., `helm/values.yaml`, `k8s/*.yaml`), also verify those files don't contain `BACKTEST_DEV_AUTH=true`

**Auth Stub Governance:**
```python
# tests/apps/web_console/test_auth_governance.py
import os
from pathlib import Path
import pytest

def load_environment_from_files(env_file: str, compose_file: str) -> dict[str, str]:
    """Load environment variables from env file and docker-compose.

    NOTE: Uses regex-based parsing for docker-compose to avoid PyYAML dependency.
    This is sufficient for checking BACKTEST_DEV_AUTH=true patterns.
    """
    import re
    env_vars: dict[str, str] = {}
    # Check .env file if exists
    env_path = Path(env_file)
    if env_path.exists():
        for line in env_path.read_text().splitlines():
            if "=" in line and not line.startswith("#"):
                key, value = line.split("=", 1)
                env_vars[key.strip()] = value.strip().strip('"')
    # Also check docker-compose environment section (in project root)
    # Use regex instead of yaml to avoid PyYAML dependency
    compose_path = Path(compose_file)
    if compose_path.exists():
        content = compose_path.read_text()
        # Pattern 1: Direct assignment - BACKTEST_DEV_AUTH=true or "true"
        direct_pattern = re.compile(
            r'^\s*-?\s*([A-Z_][A-Z0-9_]*)(?:=|:\s*)(["\']?)(\w+)\2\s*$',
            re.MULTILINE
        )
        for match in direct_pattern.finditer(content):
            key, _, value = match.groups()
            env_vars[key] = value

        # Pattern 2: Env substitution with defaults - ${BACKTEST_DEV_AUTH:-true}
        # This catches cases like: BACKTEST_DEV_AUTH=${BACKTEST_DEV_AUTH:-true}
        subst_pattern = re.compile(
            r'([A-Z_][A-Z0-9_]*)=\$\{[^}]*:-(\w+)\}',
            re.MULTILINE
        )
        for match in subst_pattern.finditer(content):
            key, default_value = match.groups()
            # Only set if not already set by direct pattern (direct takes precedence)
            if key not in env_vars:
                env_vars[key] = default_value
    return env_vars


def _check_no_dev_auth(env_vars: dict[str, str], env_name: str) -> None:
    """Assert BACKTEST_DEV_AUTH is not enabled."""
    assert env_vars.get("BACKTEST_DEV_AUTH", "false").lower() != "true", (
        f"BACKTEST_DEV_AUTH=true is set in {env_name} config! "
        "This must be removed before T5.3 goes to prod/staging."
    )


def test_no_dev_auth_in_prod():
    """CI guard: dev auth stub must not be enabled in production."""
    prod_env = load_environment_from_files(".env.prod", "docker-compose.prod.yml")
    _check_no_dev_auth(prod_env, "production")


def test_no_dev_auth_in_staging():
    """CI guard: dev auth stub must not be enabled in staging."""
    staging_env = load_environment_from_files(".env.staging", "docker-compose.staging.yml")
    _check_no_dev_auth(staging_env, "staging")


def test_no_auth_stub_references_after_t61():
    """
    CI guard: After T6.1 ships, no code should reference backtest_requires_auth.

    This test detects manual import regressions where developers accidentally
    import the stub decorator instead of the real @requires_auth after T6.1.
    """
    import subprocess

    # Check if T6.1 has shipped by looking for explicit completion marker.
    # CRITICAL: Cannot use streamlit_helpers.py existence (it already exists).
    # Instead, check for T6.1-specific OAuth2 completion indicator:
    # - Presence of AUTH_OAUTH2_COMPLETE flag in auth config
    # - OR absence of backtest_auth.py (stub deleted per rollback path)
    t61_marker = Path("apps/web_console/auth/backtest_auth.py")
    if t61_marker.exists():
        # Stub file still exists = T6.1 not yet complete, skip this test
        pytest.skip("T6.1 not yet shipped; auth stub backtest_auth.py still exists")

    # T6.1 complete (stub deleted) - verify no stale references remain
    result = subprocess.run(
        ["grep", "-r", "backtest_requires_auth", "apps/"],
        capture_output=True,
        text=True,
    )

    # grep returns 0 if matches found, 1 if no matches, 2+ on error
    if result.returncode == 0:
        pytest.fail(
            f"Found backtest_requires_auth references after T6.1 shipped! "
            f"These must be replaced with @requires_auth:\n{result.stdout}"
        )
    # returncode 1 = no matches = test passes
```

```python
# apps/web_console/auth/backtest_auth.py
import functools
import os
from typing import Any
from collections.abc import Callable

import streamlit as st

from apps.web_console.auth.streamlit_helpers import requires_auth

def backtest_requires_auth(func: Callable[..., Any]) -> Callable[..., Any]:
    """Auth decorator with dev-mode fallback for T5.3.

    CRITICAL: Dev stub must set the same session keys as real OAuth2 auth:
    - authenticated, username, user_id, auth_method, session_id
    This ensures get_user_info() works correctly in both modes.
    """
    if os.getenv("BACKTEST_DEV_AUTH", "false").lower() == "true":
        # Dev mode: set stub user with same session shape as OAuth2
        # CRITICAL: Must include role and strategies for RBAC parity
        @functools.wraps(func)
        def wrapper(*args: Any, **kwargs: Any) -> Any:
            st.session_state["authenticated"] = True
            st.session_state["username"] = "dev_user"
            st.session_state["user_id"] = "dev_user_id"
            st.session_state["auth_method"] = "dev_stub"
            st.session_state["session_id"] = "dev_session"
            st.session_state["role"] = "operator"  # RBAC role for permission checks
            st.session_state["strategies"] = ["*"]  # Access to all strategies
            return func(*args, **kwargs)
        return wrapper
    else:
        # Production: use real auth
        return requires_auth(func)
```

**Deliverables:**
- Backtest configuration form (alpha selection, date range, weight method)
- Job status polling with progress bar
- Job status polling with progress bar **using progressive backoff** (e.g., 2s ‚Üí 5s ‚Üí 10s while pending/running; 30s after terminal)
- Results visualization (equity curve, drawdown, IC time series)
- Strategy comparison view (side-by-side metrics)
- Export functionality (CSV, JSON)

**Implementation:**
```python
# apps/web_console/pages/backtest.py
import os
import json
from contextlib import contextmanager
from typing import Generator

import streamlit as st
from streamlit_autorefresh import st_autorefresh
from redis import Redis
from psycopg.rows import dict_row
from psycopg_pool import ConnectionPool

from apps.web_console.auth.backtest_auth import backtest_requires_auth
from apps.web_console.auth.streamlit_helpers import get_user_info
from libs.backtest.job_queue import BacktestJobQueue, BacktestJobConfig, JobPriority
from libs.backtest.result_storage import BacktestResultStorage
from libs.alpha.alpha_library import CANONICAL_ALPHAS  # Use existing alpha registry

# CRITICAL: BacktestJobQueue requires SYNC pool (not async)
# The existing get_db_pool() returns AsyncConnectionAdapter for async operations.
# We need a separate sync pool for BacktestJobQueue which uses `with pool.connection():`
@st.cache_resource
def get_sync_db_pool() -> ConnectionPool:
    """Get synchronous psycopg connection pool for BacktestJobQueue.

    CRITICAL: This is separate from the async pool in db_pool.py because
    BacktestJobQueue uses synchronous `with pool.connection():` syntax.
    """
    database_url = os.getenv("DATABASE_URL")
    if not database_url:
        raise RuntimeError("DATABASE_URL not configured")
    pool = ConnectionPool(conninfo=database_url, min_size=1, max_size=5)
    pool.open()
    return pool

def _get_redis_url() -> str:
    """Build Redis URL from environment, falling back to container defaults."""
    redis_url = os.getenv("REDIS_URL")
    if redis_url:
        return redis_url
    # Fallback: build from individual vars (container-compatible)
    host = os.getenv("REDIS_HOST", "redis")  # 'redis' is docker service name
    port = os.getenv("REDIS_PORT", "6379")
    db = os.getenv("REDIS_DB", "0")
    return f"redis://{host}:{port}/{db}"


@st.cache_resource
def get_sync_redis_client() -> Redis:
    """Get synchronous Redis client for BacktestJobQueue.

    CRITICAL: Separate from async Redis adapter in db_pool.py.
    Uses _get_redis_url() for container compatibility (not hardcoded localhost).
    """
    return Redis.from_url(_get_redis_url())

@contextmanager
def get_job_queue() -> Generator[BacktestJobQueue, None, None]:
    """Get job queue with sync psycopg connection pool."""
    redis = get_sync_redis_client()
    pool = get_sync_db_pool()
    queue = BacktestJobQueue(redis, pool)
    try:
        yield queue
    finally:
        # Do not close the cached pool; Streamlit pages reuse this singleton
        pass

def get_available_alphas() -> list[str]:
    """Get list of registered alpha names from alpha library."""
    return list(CANONICAL_ALPHAS.keys())

VALID_STATUSES = {"pending", "running", "completed", "failed", "cancelled"}


def get_poll_interval_ms(elapsed_seconds: float) -> int:
    """Progressive polling: start fast, then back off for long/terminal jobs."""
    if elapsed_seconds < 30:
        return 2000
    if elapsed_seconds < 60:
        return 5000
    if elapsed_seconds < 300:
        return 10_000
    return 30_000

def get_user_jobs(created_by: str, status: list[str]) -> list[dict]:
    """
    Query jobs for a user with given statuses.

    Uses sync query against Postgres backtest_jobs table.

    CRITICAL: Use DB status vocabulary (pending, running, completed, failed, cancelled),
    NOT RQ vocabulary (queued, started, finished).

    NOTE: "expired" jobs are represented as status="failed" with error_message
    indicating timeout/expiration cause.
    """
    invalid = set(status) - VALID_STATUSES
    if invalid:
        raise ValueError(f"Invalid statuses: {invalid}. Valid: {VALID_STATUSES}")

    pool = get_sync_db_pool()
    # Include error_message and summary metrics for terminal job display and comparison
    sql = """
        SELECT job_id, alpha_name, start_date, end_date, status, created_at,
               error_message, mean_ic, icir, hit_rate, coverage, average_turnover
        FROM backtest_jobs
        WHERE created_by = %s AND status = ANY(%s)
        ORDER BY created_at DESC
        LIMIT 50
    """
    with pool.connection() as conn, conn.cursor(row_factory=dict_row) as cur:
        cur.execute(sql, (created_by, status))
        jobs = cur.fetchall()

    # Fetch progress from Redis for each job (reuse cached client)
    redis = get_sync_redis_client()
    result = []
    for job in jobs:
        progress_raw = redis.get(f"backtest:progress:{job['job_id']}")
        progress = json.loads(progress_raw) if progress_raw else {"pct": 0}
        result.append({
            "job_id": job["job_id"],
            "alpha_name": job["alpha_name"],
            "start_date": str(job["start_date"]),
            "end_date": str(job["end_date"]),
            "progress_pct": progress.get("pct", 0),
            "status": job["status"],
            "created_at": job["created_at"].isoformat() if job.get("created_at") else None,
            # Terminal job fields for error display and comparison
            "error_message": job.get("error_message"),
            "mean_ic": job.get("mean_ic"),
            "icir": job.get("icir"),
            "hit_rate": job.get("hit_rate"),
            "coverage": job.get("coverage"),
            "average_turnover": job.get("average_turnover"),
        })
    return result

def get_current_username() -> str:
    """Get username from session using standard auth pattern.

    Uses get_user_info() which reads from st.session_state keys set by
    both OAuth2 auth and dev stub (authenticated, username, user_id, etc.).
    """
    try:
        user_info = get_user_info()
        return user_info.get("username", "anonymous")
    except RuntimeError:
        # Not authenticated - should not happen if @backtest_requires_auth is used
        st.warning("No authenticated user in session")
        return "anonymous"

def _get_user_with_role() -> dict[str, Any]:
    """Get user info including role for RBAC checks.

    CRITICAL: get_user_info() only returns username/email/user_id/auth_method/session_id.
    It does NOT include role/strategies. We must read role from session_state directly.
    The dev stub and OAuth2 both set st.session_state["role"].
    """
    user_info = get_user_info()
    # Add role from session_state (set by both dev stub and OAuth2)
    user_info["role"] = st.session_state.get("role", "viewer")  # Default to viewer (most restrictive)
    user_info["strategies"] = st.session_state.get("strategies", [])
    return user_info


@backtest_requires_auth
def render_backtest_page():
    """Backtest configuration and results page."""
    from apps.web_console.auth.permissions import Permission, has_permission

    # RBAC: Require VIEW_PNL permission to access backtest UI
    # CRITICAL: Use _get_user_with_role() NOT get_user_info() - role is in session_state
    user_info = _get_user_with_role()
    if not has_permission(user_info, Permission.VIEW_PNL):
        st.error("Permission denied: VIEW_PNL required to access Backtest Manager.")
        st.stop()
        return

    st.header("Backtest Runner")

    tab1, tab2, tab3 = st.tabs(["New Backtest", "Running Jobs", "Results"])

    with tab1:
        render_backtest_form()

    with tab2:
        render_running_jobs()

    with tab3:
        render_backtest_results()

def render_backtest_form():
    """Render backtest configuration form."""
    with st.form("backtest_config"):
        col1, col2 = st.columns(2)

        with col1:
            alpha_name = st.selectbox(
                "Alpha Signal",
                options=get_available_alphas(),
                help="Select the alpha signal to backtest"
            )
            start_date = st.date_input("Start Date")
            end_date = st.date_input("End Date")

        with col2:
            weight_method = st.selectbox(
                "Weight Method",
                options=["zscore", "quantile", "rank"],  # Must match BacktestJobConfig.WeightMethod
                help="How to convert signals to portfolio weights"
            )
            priority_str = st.selectbox(
                "Priority",
                options=["normal", "high", "low"],
            )

        submitted = st.form_submit_button("Run Backtest", type="primary")

        if submitted:
            # Validate date range
            if end_date <= start_date:
                st.error("End date must be after start date")
                return

            # Validate priority enum
            try:
                priority = JobPriority(priority_str)
            except ValueError:
                st.error(f"Invalid priority: {priority_str}")
                return

            config = BacktestJobConfig(
                alpha_name=alpha_name,
                start_date=start_date,
                end_date=end_date,
                weight_method=weight_method,
            )

            # Pass created_by from authenticated session
            created_by = get_current_username()
            with get_job_queue() as queue:
                job = queue.enqueue(config, priority=priority, created_by=created_by)
            st.success(f"Backtest queued! Job ID: {job.id}")
            st.rerun()

def render_running_jobs():
    """Render list of running/queued jobs with status."""
    created_by = get_current_username()

    # Progressive polling with st_autorefresh
    elapsed = st.session_state.get("backtest_poll_elapsed", 0.0)
    interval_ms = get_poll_interval_ms(elapsed)
    st_autorefresh(interval=interval_ms, key="backtest_poll")
    st.session_state["backtest_poll_elapsed"] = elapsed + interval_ms / 1000

    # Fetch jobs for current user only (use DB statuses, not RQ)
    # Progressive polling: refresh every 2s initially, back off to 5s after 30s, 10s after 60s.
    jobs = get_user_jobs(created_by=created_by, status=["pending", "running"])

    if not jobs:
        st.session_state["backtest_poll_elapsed"] = 0

    for job in jobs:
        with st.container():
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1:
                st.write(f"**{job['alpha_name']}** ({job['start_date']} to {job['end_date']})")
            with col2:
                st.progress(job['progress_pct'] / 100)
            with col3:
                if st.button("Cancel", key=f"cancel_{job['job_id']}"):
                    with get_job_queue() as queue:
                        queue.cancel_job(job['job_id'])
                    st.rerun()

def render_backtest_results():
    """Render completed backtest results with visualization."""
    # Result selection, metrics display, charts
    ...
```

**Files to Create:**
- `apps/web_console/pages/backtest.py`
- `apps/web_console/auth/backtest_auth.py`
- `apps/web_console/components/backtest_form.py`
- `apps/web_console/components/backtest_results.py`
- `apps/web_console/components/equity_curve_chart.py`
- `apps/web_console/components/drawdown_chart.py`
- `apps/web_console/components/ic_timeseries_chart.py`
- `apps/web_console/utils/sync_db_pool.py` (sync pool helper for BacktestJobQueue)
- `tests/apps/web_console/test_backtest_page.py`
- `tests/apps/web_console/test_backtest_job_status.py`
- `tests/apps/web_console/test_auth_governance.py` (CI guard for dev auth)
- `tests/apps/web_console/test_auth_enforcement.py` (OAuth2 enforcement in non-dev)
- `docs/CONCEPTS/backtest-web-ui.md`
- `docs/ADRs/ADR-0025-backtest-ui-worker-contract.md`

**Files to Modify:**
- `apps/web_console/requirements.txt` - Add `streamlit-autorefresh>=1.0.0`, `psycopg-pool>=3.1.0`
- `apps/web_console/app.py` - Add "Backtest Manager" to navigation
- `apps/web_console/config.py` - Add `FEATURE_BACKTEST_MANAGER` flag

---
---
## Acceptance Criteria
### T5.3 Web UI
- [ ] Form validation prevents invalid date ranges (end < start)
- [ ] UI uses progressive polling (2s‚Üí5s‚Üí10s‚Üí30s as job runs longer); progress reflects worker updates (‚â§30s emit cadence)
- [ ] Equity curve renders for backtests with 1000+ daily points
- [ ] Side-by-side comparison shows ‚â•5 metrics for 2+ backtests
- [ ] Failed jobs (including timeouts/expired) display error message clearly (note: "expired" = status "failed" with timeout error_message)
- [ ] **Auth Stub Security:** CI fails if `BACKTEST_DEV_AUTH=true` in prod/staging configs (`test_no_dev_auth_in_prod`, `test_no_dev_auth_in_staging`)
- [ ] **Auth Stub Cleanup:** After T6.1 ships, CI fails if `backtest_requires_auth` references exist (`test_no_auth_stub_references_after_t61`)
- [ ] **Auth Enforcement:** Web UI requires real OAuth2 auth in non-dev environments (verified by integration test)

---

## Implementation Tracking

**Branch:** `feature/P4T4-T5.3-backtest-web-ui`
**Started:** 2025-12-17

### Component Breakdown

| # | Component | Status | Files |
|---|-----------|--------|-------|
| C1 | Auth Stub & Governance Tests | ‚è≥ In Progress | `backtest_auth.py`, `test_auth_governance.py` |
| C2 | Backtest Form Component | üìã Pending | `backtest_form.py` |
| C3 | Visualization Components | üìã Pending | `equity_curve_chart.py`, `ic_timeseries_chart.py`, `drawdown_chart.py`, `backtest_results.py` |
| C4 | Main Backtest Page (incl. comparison & export) | üìã Pending | `pages/backtest.py`, `app.py`, `config.py` |
| C5 | Test Suite | üìã Pending | `test_backtest_page.py`, `test_backtest_job_status.py`, `test_auth_enforcement.py` |
| C6 | Documentation | üìã Pending | `backtest-web-ui.md`, `ADR-0025-*.md` |

### Dependencies Verified
- [x] T5.1 Job Queue: `libs/backtest/job_queue.py` - Complete
- [x] T5.2 Result Storage: `libs/backtest/result_storage.py` - Complete
- [x] Database Schema: `db/migrations/0008_create_backtest_jobs.sql` - Complete
- [x] Alpha Registry: `libs/alpha/alpha_library.py` - Complete (CANONICAL_ALPHAS)
- [ ] T6.1 Auth: Pending ‚Üí Using dev-mode stub

### UI Dependency Updates Required

All dependencies are managed in `pyproject.toml`. The following were added for T5.3:
```toml
# Web console UI dependencies (T5.3)
streamlit-autorefresh = "^1.0.1"  # Progressive polling for job status

# Note: rq and structlog are shared dependencies used by both
# the backtest worker and web console
```

### Environment Configuration Required

Add to `docker-compose.yml` web_console service environment:
```yaml
services:
  web_console:
    environment:
      - REDIS_URL=redis://${REDIS_HOST:-redis}:${REDIS_PORT:-6379}/${REDIS_DB:-0}
```

NOTE: The plan's `get_sync_redis_client()` must build URL from env vars, not hardcode localhost:
```python
def _get_redis_url() -> str:
    """Build Redis URL from environment, falling back to container defaults."""
    redis_url = os.getenv("REDIS_URL")
    if redis_url:
        return redis_url
    # Fallback: build from individual vars (container-compatible)
    host = os.getenv("REDIS_HOST", "redis")  # 'redis' is docker service name
    port = os.getenv("REDIS_PORT", "6379")
    db = os.getenv("REDIS_DB", "0")
    return f"redis://{host}:{port}/{db}"
```

### Key Implementation Notes

1. **Alpha Registry**: Use `CANONICAL_ALPHAS.keys()` from `libs/alpha/alpha_library.py` (NOT `get_registered_alphas()` which doesn't exist)

2. **Weight Method**: Use job_queue's `WeightMethod = Literal["zscore", "quantile", "rank"]` - UI options must match exactly

3. **Progressive Polling**: Use `streamlit-autorefresh` package with `get_poll_interval_ms()` function

4. **DB Pool**: Create `get_sync_db_pool()` locally - BacktestJobQueue requires sync pool (existing `get_db_pool()` is async)

5. **Auth Session**: Dev stub must set same session keys as OAuth2: `authenticated`, `username`, `user_id`, `auth_method`, `session_id`, **`role`, `strategies`**

6. **Expired Jobs**: Represented as status "failed" with error_message indicating timeout cause

7. **RBAC Role Access**: `get_user_info()` does NOT include role/strategies. Use `_get_user_with_role()` wrapper to add `role` and `strategies` from `st.session_state` before calling `has_permission()`

8. **T6.1 Marker**: Use `backtest_auth.py` existence as T6.1 completion marker (NOT `streamlit_helpers.py` which already exists). When T6.1 ships and stub is deleted, governance test activates

9. **OAuth2 Role/Strategies (T6.1 Requirement)**: Current OAuth2 auth does NOT set `st.session_state["role"]` or `["strategies"]`. When T6.1 ships, OAuth2 must populate these session keys for RBAC to work correctly. The dev stub already sets them as a reference implementation

10. **Export Permission**: All export buttons require `Permission.EXPORT_DATA`. Use `has_permission(user_info, Permission.EXPORT_DATA)` check before rendering download buttons

11. **Sync Pool Placement (LOW)**: Place sync pool helper in `apps/web_console/utils/sync_db_pool.py` for consistency with existing `db_pool.py`. This centralizes connection management and allows shared logging/monitoring. Pool uses small `max_size=5` to avoid resource contention during Streamlit reloads.

12. **Auth Helper Migration Path (LOW)**: Currently using `get_user_info()` from `streamlit_helpers.py`. When T6.1 adds role/strategies to session state, consider migrating to `session_manager.get_current_user()` which includes session metadata (expiry, last_activity). The wrapper `_get_user_with_role()` abstracts this transition - only the wrapper needs updating when T6.1 ships.

13. **Pool Cleanup (LOW)**: Sync `ConnectionPool` maintains long-lived connections. For Streamlit's reload behavior, the `@st.cache_resource` decorator ensures the pool persists across reruns. If connection leaks are observed, add explicit `pool.close()` in a cleanup handler or reduce `max_size`.

14. **Export Button Visibility (T6.1 Gap)**: Until T6.1 populates role/strategies in OAuth2 sessions, authenticated users will default to "viewer" role which lacks `EXPORT_DATA` permission. Export buttons will be hidden/disabled for non-dev users. This is acceptable as backtest functionality still works - only exports are gated.

15. **Governance Test Config Files (LOW)**: Repository has `docker-compose.staging.yml` but no `docker-compose.prod.yml`. Governance tests should skip gracefully when config files don't exist (already handled via `Path.exists()` checks). For prod, we rely on `.env.prod` or cloud deployment configs which should be checked separately.

### Visualization Components (C3) - Detailed

| Component | File | Purpose |
|-----------|------|---------|
| Equity Curve | `equity_curve_chart.py` | Cumulative returns over time (Plotly line chart) |
| Drawdown Chart | `drawdown_chart.py` | Maximum drawdown visualization (Plotly area chart) |
| IC Time Series | `ic_timeseries_chart.py` | IC and Rank IC with rolling mean overlay |
| Results Display | `backtest_results.py` | Metrics summary + all charts + export buttons |

**Visualization Calculations:**

1. **Equity Curve** (`equity_curve_chart.py`):
   ```python
   # Input: daily_portfolio_returns (date, return)
   # Compute cumulative return: (1 + r1) * (1 + r2) * ... - 1
   cumulative = (1 + df["return"]).cumprod() - 1
   # X-axis: date, Y-axis: cumulative_return (percentage)
   ```

2. **Drawdown Chart** (`drawdown_chart.py`):
   ```python
   # Compute running max and drawdown from cumulative returns
   cumulative = (1 + df["return"]).cumprod()
   running_max = cumulative.cummax()
   drawdown = (cumulative - running_max) / running_max
   # Plot as Plotly area chart (negative values, filled to 0)
   ```

3. **IC Time Series** (`ic_timeseries_chart.py`):
   ```python
   # Input: daily_ic (date, ic, rank_ic)
   # Rolling mean: 21-day (1 month) window
   rolling_ic = df["ic"].rolling(window=21, min_periods=5).mean()
   rolling_rank_ic = df["rank_ic"].rolling(window=21, min_periods=5).mean()
   # Plot: raw IC (light), rolling mean (bold) for both IC and Rank IC
   ```

**Error Handling in Charts:**
- If daily data is empty, display `st.info("No data available")`
- If computation fails, catch exception and display `st.error()` with details
- Handle NaN values gracefully (drop or interpolate based on chart type)

### Strategy Comparison View (C4) - Detailed

The Results tab includes a **comparison mode**:
- Multi-select dropdown to choose 2+ completed backtests
- Side-by-side metrics table showing ‚â•5 metrics: mean_ic, icir, hit_rate, coverage, average_turnover
- Overlay charts for equity curves
- Export comparison as CSV/JSON

### Export Functionality (C4) - Detailed

Export handlers using Streamlit download buttons with **separate files per data type** (not merged).

**RBAC Gating**: All export buttons require `Permission.EXPORT_DATA`:
```python
from apps.web_console.auth.permissions import Permission, has_permission

def render_export_buttons(result: BacktestResult, user_info: dict[str, Any]) -> None:
    """Render export buttons if user has EXPORT_DATA permission."""
    if not has_permission(user_info, Permission.EXPORT_DATA):
        st.info("Export requires EXPORT_DATA permission.")
        return

    # Render download buttons...
    col1, col2, col3 = st.columns(3)
    with col1:
        st.download_button("üìä Signals CSV", signals_csv, "signals.csv", "text/csv")
    # ... etc
```

**CSV Exports (separate buttons):**
1. `signals.csv`: date, permno, signal (from daily_signals.parquet)
2. `weights.csv`: date, permno, weight (from daily_weights.parquet)
3. `ic_series.csv`: date, ic, rank_ic (from daily_ic.parquet - no permno, per-date)
4. `returns.csv`: date, cumulative_return (computed from daily_portfolio_returns)
5. `metrics_summary.csv`: Single row with mean_ic, icir, hit_rate, coverage, average_turnover

**JSON Export:**
- `result.json`: Full metrics summary + config + reproducibility metadata (snapshot_id, dataset_version_ids)

### Terminal/Error Job Handling (C4) - Detailed

**Running Jobs tab:**
- Query statuses: `["pending", "running"]`
- Polling: Progressive backoff (2s‚Üí5s‚Üí10s‚Üí30s)
- Reset elapsed timer when:
  - No active jobs remain
  - Job set changes (new job added or job completes)
  - Newest job `created_at` is later than last seen (detect new submissions)

```python
# Polling reset logic
current_job_ids = {j["job_id"] for j in jobs}
last_job_ids = st.session_state.get("backtest_last_job_ids", set())
newest_created = max((j["created_at"] for j in jobs), default=None)
last_newest = st.session_state.get("backtest_last_newest", None)

if not jobs or current_job_ids != last_job_ids or newest_created != last_newest:
    st.session_state["backtest_poll_elapsed"] = 0.0

st.session_state["backtest_last_job_ids"] = current_job_ids
st.session_state["backtest_last_newest"] = newest_created
```

**Results tab:**
- Query statuses: `["completed", "failed", "cancelled"]`
- Display error_message column for failed jobs with red styling
- Show cancelled jobs with warning styling
- Polling: Fixed 30s interval (terminal states don't need fast updates)

**Error Display:**
```python
if job["status"] == "failed":
    st.error(f"‚ùå Failed: {job.get('error_message', 'Unknown error')}")
elif job["status"] == "cancelled":
    st.warning(f"‚ö†Ô∏è Cancelled by user")
```

### Auth Enforcement Integration Test (C5) - Detailed

Add `test_auth_enforcement.py`:
```python
def test_backtest_page_requires_auth_in_non_dev_mode(monkeypatch):
    """Verify OAuth2 auth is required when BACKTEST_DEV_AUTH is not set."""
    monkeypatch.delenv("BACKTEST_DEV_AUTH", raising=False)
    # Mock streamlit session without auth
    # Attempt to call render_backtest_page()
    # Assert st.stop() is called (auth redirect triggered)
```

