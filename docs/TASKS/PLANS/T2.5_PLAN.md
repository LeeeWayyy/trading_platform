# T2.5 Alpha Research Framework - Implementation Plan

**Component:** T2.5-Alpha-Research-Framework
**Effort:** 4-5 days
**Created:** 2025-12-08
**Updated:** 2025-12-08 (v3 - fail-fast forward return contract)
**Status:** Planning

---

## 1. Overview

Build the Alpha Research Framework for quantitative signal research with:
- Alpha signal definition framework (Protocol-based)
- AlphaMetricsAdapter with Qlib wrapper and local Polars fallback
- Point-in-time backtesting engine with strict PIT data contracts
- Comprehensive metrics: IC, ICIR, Rank IC, Grouped IC, decay curves, turnover
- New metrics: Autocorrelation, Hit Rate, Coverage %, Long/Short Spread

---

## 2. Dependencies Analysis

### Confirmed Available:
- **T2.1 Factor Builder**: `libs/factors/factor_builder.py` - COMPLETE
- **T1.6 Dataset Versioning**: `libs/data_quality/versioning.py` - COMPLETE
- **Qlib 0.9.7**: Installed, available functions:
  - `backtest_daily`, `risk_analysis`, `indicator_analysis`, `long_short_backtest`
  - Note: No `get_group_return` - will implement grouped IC locally
- **CRSP/Compustat Providers**: `libs/data_providers/` - COMPLETE

### Integration Points:
- `DatasetVersionManager` for PIT snapshots and reproducibility
- `FactorBuilder._get_pit_sector_mappings()` for GICS sector classification (reuse existing logic)
- `ManifestManager` for dataset version tracking

---

## 3. Architecture

### Module Structure
```
libs/alpha/
├── __init__.py           # Public API exports
├── alpha_definition.py   # AlphaDefinition Protocol + base classes
├── alpha_library.py      # Canonical alpha implementations
├── metrics.py            # AlphaMetricsAdapter (Qlib + local)
├── research_platform.py  # PITBacktester, BacktestResult
├── analytics.py          # Decay curves, turnover, grouped analysis
├── portfolio.py          # Signal→Weight conversion for turnover
└── exceptions.py         # PITViolationError, MissingForwardReturnError
```

### Custom Exceptions
```python
# libs/alpha/exceptions.py
class AlphaResearchError(Exception):
    """Base exception for alpha research framework."""
    pass

class PITViolationError(AlphaResearchError):
    """Raised when point-in-time data contract is violated."""
    pass

class MissingForwardReturnError(AlphaResearchError):
    """Raised when forward return horizon exceeds snapshot (FAIL-FAST)."""
    pass
```

### Key Classes

```python
# Alpha Definition Protocol
class AlphaDefinition(Protocol):
    """Protocol for alpha signal computation."""
    name: str
    universe_filter: str  # 'all', 'large_cap', 'mid_cap'

    def compute(
        self,
        prices: pl.DataFrame,
        fundamentals: pl.DataFrame | None,
        as_of_date: date,
    ) -> pl.DataFrame:
        """Return DataFrame with [permno, date, signal]."""
        ...

# Metrics Adapter (dual backend)
class AlphaMetricsAdapter:
    """Compute alpha metrics with Qlib or local fallback."""

    def __init__(self, prefer_qlib: bool = True):
        self._use_qlib = prefer_qlib and self._qlib_ready()

    def _qlib_ready(self) -> bool:
        """Check Qlib import AND initialization readiness."""
        try:
            import qlib
            from qlib.contrib.evaluate import risk_analysis
            # Verify Qlib is importable; init is not required for pure metrics
            return True
        except ImportError:
            logger.info("Qlib not available, using local fallback")
            return False

    # Core metrics
    def compute_ic(signal, returns, method="rank") -> float
    def compute_icir(signal, returns, window=20) -> float
    def compute_grouped_ic(signal, returns, groups) -> pl.DataFrame
    def compute_decay_curve(signal, returns, horizons) -> pl.DataFrame

    # New metrics
    def compute_autocorrelation(signal, lags=[1, 5, 20]) -> dict[int, float]
    def compute_hit_rate(signal, returns) -> float
    def compute_coverage(signal, universe_size) -> float
    def compute_long_short_spread(signal, returns, decile=10) -> float

# Signal to Weight Converter (for turnover calculation)
class SignalToWeight:
    """Convert raw alpha signals to portfolio weights."""

    def __init__(self, method: Literal["zscore", "quantile", "rank"] = "zscore"):
        self.method = method

    def convert(self, signal: pl.DataFrame) -> pl.DataFrame:
        """
        Convert signal to weights.

        Methods:
        - zscore: weights = z-score / sum(|z-score|) (signed, sums to 0)
        - quantile: weights based on quantile bucket assignment
        - rank: weights = (rank - mean_rank) / sum(|rank - mean_rank|)

        Returns DataFrame with [permno, date, weight].
        """
        ...

# PIT Backtester with strict data contracts
class PITBacktester:
    """Point-in-time correct backtesting engine."""

    def __init__(
        self,
        version_manager: DatasetVersionManager,
        crsp_provider: CRSPLocalProvider,
        compustat_provider: CompustatLocalProvider,
        metrics_adapter: AlphaMetricsAdapter,
    ):
        ...

    def run_backtest(
        self,
        alpha: AlphaDefinition,
        start_date: date,
        end_date: date,
        snapshot_id: str | None = None,
        weight_method: Literal["zscore", "quantile", "rank"] = "zscore",
    ) -> BacktestResult:
        """Run PIT-correct backtest."""
        ...
```

---

## 4. Strict PIT Data Contract (Addresses HIGH Issue #1)

**CRITICAL:** All data access during backtest MUST go through snapshot-locked paths. No live provider access is permitted.

### PIT Data Flow:
```
┌─────────────────────────────────────────────────────────────────────────┐
│                      PITBacktester Data Flow                            │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  1. Snapshot Lock                                                       │
│     snapshot = version_manager.get_snapshot(snapshot_id)                │
│     ASSERT snapshot.created_at <= backtest_start_date                   │
│                                                                         │
│  2. Price Data (for signal computation)                                 │
│     prices = _get_pit_prices(as_of_date, snapshot)                      │
│     └── Uses snapshot.datasets["crsp"].date_range_end as hard cutoff    │
│     └── Filters: date <= as_of_date (no future data)                    │
│                                                                         │
│  3. Fundamentals (for value/quality alphas)                             │
│     fundamentals = _get_pit_fundamentals(as_of_date, snapshot)          │
│     └── Uses Compustat with filing lag (datadate + 90 days)             │
│     └── Only data where datadate + 90 days <= as_of_date                │
│                                                                         │
│  4. Forward Returns (for IC calculation)                                │
│     fwd_returns = _get_pit_forward_returns(as_of_date, horizon, snap)   │
│     └── Returns from as_of_date + 1 to as_of_date + horizon             │
│     └── MUST exist in snapshot (no live fetch)                          │
│     └── If missing, raise MissingForwardReturnError (FAIL-FAST)         │
│                                                                         │
│  5. Sector Classification                                               │
│     sectors = _get_pit_sectors(as_of_date, snapshot)                    │
│     └── Uses FactorBuilder._get_pit_sector_mappings() logic             │
│     └── GICS codes with filing lag                                      │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

### PIT Enforcement:
```python
class PITBacktester:
    def __init__(self, ...):
        # CRITICAL: Store references but DO NOT call providers directly
        self._version_manager = version_manager
        self._crsp_provider = crsp_provider  # For snapshot-locked access only
        self._compustat_provider = compustat_provider
        self._snapshot: SnapshotManifest | None = None

    def _ensure_snapshot_locked(self) -> None:
        """Assert snapshot is locked before any data access."""
        if self._snapshot is None:
            raise PITViolationError("No snapshot locked - call run_backtest first")

    def _get_pit_prices(self, as_of_date: date) -> pl.DataFrame:
        """Get prices strictly from snapshot with date filter."""
        self._ensure_snapshot_locked()
        crsp_snapshot = self._snapshot.datasets["crsp"]

        # Hard cutoff: snapshot date range
        if as_of_date > crsp_snapshot.date_range_end:
            raise PITViolationError(
                f"Requested {as_of_date} but snapshot ends {crsp_snapshot.date_range_end}"
            )

        # Get data path from snapshot (immutable)
        data_path = self._version_manager.get_snapshot_data_path(
            self._snapshot.version_tag, "crsp"
        )
        prices = pl.read_parquet(data_path)

        # Strict date filter: only data known at as_of_date
        return prices.filter(pl.col("date") <= as_of_date)

    def _get_pit_forward_returns(
        self, as_of_date: date, horizon: int = 1
    ) -> pl.DataFrame:
        """
        Get forward returns from snapshot.

        CRITICAL: Forward returns must exist in snapshot.
        Raises MissingForwardReturnError if horizon exceeds snapshot (FAIL-FAST).
        """
        self._ensure_snapshot_locked()
        crsp_snapshot = self._snapshot.datasets["crsp"]

        target_date = as_of_date + timedelta(days=horizon)
        if target_date > crsp_snapshot.date_range_end:
            raise MissingForwardReturnError(
                f"Forward return date {target_date} exceeds snapshot end "
                f"{crsp_snapshot.date_range_end}. Reduce backtest end_date or "
                f"horizon, or use a newer snapshot."
            )

        # ... compute returns from snapshot data
```

---

## 5. Signal-to-Weight Conversion (Addresses HIGH Issue #2)

**Problem:** Turnover metric requires portfolio weights, not raw signals.

### Solution: Explicit Weight Conversion Step
```python
# libs/alpha/portfolio.py
class SignalToWeight:
    """Convert raw alpha signals to portfolio weights for turnover calculation."""

    def __init__(
        self,
        method: Literal["zscore", "quantile", "rank"] = "zscore",
        long_only: bool = False,
        target_leverage: float = 1.0,
    ):
        """
        Args:
            method: Weight calculation method
            long_only: If True, only positive weights (no shorts)
            target_leverage: Sum of absolute weights (default 1.0 = 100%)
        """
        self.method = method
        self.long_only = long_only
        self.target_leverage = target_leverage

    def convert(self, signals: pl.DataFrame) -> pl.DataFrame:
        """
        Convert signals to weights.

        Input: DataFrame with [permno, date, signal]
        Output: DataFrame with [permno, date, weight]

        Weight properties:
        - zscore: weights sum to 0 (dollar-neutral), |weights| sum to target_leverage
        - quantile: top quantile = +1/n, bottom = -1/n, middle = 0
        - rank: rank-based, dollar-neutral
        """
        if signals.height == 0:
            return signals.with_columns(pl.lit(0.0).alias("weight")).drop("signal")

        # Filter valid signals
        valid = signals.filter(pl.col("signal").is_not_null())

        if self.method == "zscore":
            return self._zscore_weights(valid)
        elif self.method == "quantile":
            return self._quantile_weights(valid)
        elif self.method == "rank":
            return self._rank_weights(valid)

    def _zscore_weights(self, signals: pl.DataFrame) -> pl.DataFrame:
        """Z-score based weights (dollar-neutral)."""
        return signals.with_columns([
            (pl.col("signal") - pl.col("signal").mean())
            .over("date")
            .alias("zscore")
        ]).with_columns([
            # Normalize to target leverage
            (pl.col("zscore") / pl.col("zscore").abs().sum().over("date") * self.target_leverage)
            .alias("weight")
        ]).drop(["signal", "zscore"])


class TurnoverCalculator:
    """Calculate portfolio turnover from weight time series."""

    def compute_daily_turnover(self, weights: pl.DataFrame) -> pl.DataFrame:
        """
        Compute daily turnover.

        Formula: turnover_t = sum(|weight_t - weight_{t-1}|) / 2

        Returns: DataFrame with [date, turnover]
        """
        # Sort by permno, date for lag calculation
        sorted_weights = weights.sort(["permno", "date"])

        # Compute weight changes
        weight_changes = sorted_weights.with_columns([
            (pl.col("weight") - pl.col("weight").shift(1).over("permno"))
            .abs()
            .alias("weight_change")
        ])

        # Aggregate by date
        daily_turnover = weight_changes.group_by("date").agg([
            (pl.col("weight_change").sum() / 2).alias("turnover")
        ]).sort("date")

        return daily_turnover

    def compute_average_turnover(self, weights: pl.DataFrame) -> float:
        """Average daily turnover over the period."""
        daily = self.compute_daily_turnover(weights)
        return daily.select(pl.col("turnover").mean()).item()
```

### Integration with Backtest:
```python
class BacktestResult:
    # ... existing fields ...

    # Turnover (now well-defined)
    weight_method: str  # "zscore", "quantile", "rank"
    daily_weights: pl.DataFrame  # [permno, date, weight]
    daily_turnover: pl.DataFrame  # [date, turnover]
    average_turnover: float
```

---

## 6. Grouped IC with GICS (Addresses MEDIUM Issue #1)

**Decision:** Use GICS for sector classification (matches Factor Builder implementation).

### GICS Integration:
```python
class AlphaMetricsAdapter:
    def compute_grouped_ic(
        self,
        signal: pl.DataFrame,
        returns: pl.DataFrame,
        sector_mapping: pl.DataFrame,  # [permno, date, gics_sector]
    ) -> pl.DataFrame:
        """
        Compute IC per GICS sector.

        Returns: DataFrame with [gics_sector, ic, rank_ic, n_stocks]
        """
        # Join signal, returns, and sectors
        joined = signal.join(returns, on=["permno", "date"]).join(
            sector_mapping, on=["permno", "date"]
        )

        # Compute IC per sector
        results = []
        for sector in joined.select("gics_sector").unique().to_series():
            sector_data = joined.filter(pl.col("gics_sector") == sector)
            ic = self._compute_ic_single(sector_data)
            results.append({
                "gics_sector": sector,
                "ic": ic["pearson_ic"],
                "rank_ic": ic["rank_ic"],
                "n_stocks": sector_data.height,
            })

        return pl.DataFrame(results)
```

### Tolerance Table (updated):
| Metric | Tolerance | Rationale |
|--------|-----------|-----------|
| Pearson IC | ≤3% | Sensitive to outliers |
| Rank IC | ≤1% | More stable, tighter tolerance |
| **Grouped IC** | **≤5%** | Sector grouping adds variance |
| ICIR | ≤5% | Ratio metric, moderate tolerance |
| **Decay IC** | **≤3%** | Same as Pearson IC |
| Autocorrelation | ≤2% | Direct correlation, tight |
| Hit Rate | ≤1% | Binary metric, very stable |
| Coverage | ≤0.5% | Count-based, near-exact |

---

## 7. Dual-Backend Parity (Addresses MEDIUM Issue #2)

### Extended Contract Tests:
```python
# tests/libs/alpha/test_metrics_contract.py
@pytest.mark.parametrize("backend", ["qlib", "polars"])
class TestMetricsContract:
    """Contract tests ensuring parity between Qlib and local backends."""

    @pytest.fixture
    def golden_data(self):
        """Load golden fixture: 252 days × 500 symbols."""
        return pl.read_parquet("tests/fixtures/alpha_metrics_golden.parquet")

    # Core metrics
    def test_pearson_ic_parity(self, backend, golden_data): ...
    def test_rank_ic_parity(self, backend, golden_data): ...
    def test_icir_parity(self, backend, golden_data): ...

    # Extended metrics (previously missing)
    def test_grouped_ic_parity(self, backend, golden_data):
        """Test grouped IC with GICS sectors."""
        if backend == "qlib":
            pytest.importorskip("qlib")
        adapter = AlphaMetricsAdapter(prefer_qlib=(backend == "qlib"))
        result = adapter.compute_grouped_ic(...)
        # Assert within 5% tolerance per sector

    def test_decay_curve_parity(self, backend, golden_data):
        """Test decay curve at horizons [1, 2, 5, 10, 20, 60]."""
        adapter = AlphaMetricsAdapter(prefer_qlib=(backend == "qlib"))
        result = adapter.compute_decay_curve(...)
        # Assert within 3% tolerance per horizon

    def test_long_short_spread_parity(self, backend, golden_data):
        """Test long/short spread (top - bottom decile)."""
        adapter = AlphaMetricsAdapter(prefer_qlib=(backend == "qlib"))
        result = adapter.compute_long_short_spread(...)
        # Assert within 2% tolerance

    # New metrics (local only, no Qlib equivalent)
    def test_autocorrelation(self, golden_data): ...
    def test_hit_rate(self, golden_data): ...
    def test_coverage(self, golden_data): ...
```

### Qlib Readiness Check (improved):
```python
def _qlib_ready(self) -> bool:
    """
    Check Qlib availability with proper fallback logging.

    Checks:
    1. qlib module importable
    2. qlib.contrib.evaluate available
    """
    try:
        import qlib
        from qlib.contrib.evaluate import risk_analysis
        logger.debug(f"Qlib {qlib.__version__} available, using Qlib backend")
        return True
    except ImportError as e:
        logger.info(f"Qlib not available ({e}), using local Polars backend")
        return False
    except Exception as e:
        logger.warning(f"Qlib import error: {e}, falling back to local backend")
        return False
```

---

## 8. Performance Strategy (Addresses MEDIUM Issue #3)

### Parallel Execution Design:
```python
class PITBacktester:
    def run_backtest(
        self,
        alpha: AlphaDefinition,
        start_date: date,
        end_date: date,
        snapshot_id: str | None = None,
        n_workers: int = 4,  # Parallel workers
        batch_size: int = 252,  # Days per batch (1 year)
    ) -> BacktestResult:
        """
        Run PIT-correct backtest with parallel execution.

        Performance strategy:
        1. Date-batching: Process 252 days per batch to manage memory
        2. Parallel horizons: Compute IC at multiple horizons in parallel
        3. Vectorized Polars: Use Polars lazy evaluation for large datasets
        """
        trading_days = self._get_trading_calendar(start_date, end_date)

        # Batch processing for memory efficiency
        batches = [
            trading_days[i:i + batch_size]
            for i in range(0, len(trading_days), batch_size)
        ]

        all_signals = []
        all_returns = []

        for batch in batches:
            # Prefetch all data for batch (vectorized Polars read)
            batch_start, batch_end = batch[0], batch[-1]
            prices = self._get_pit_prices_range(batch_start, batch_end)
            fundamentals = self._get_pit_fundamentals_range(batch_start, batch_end)

            # Compute signals for all dates in batch (vectorized where possible)
            for as_of_date in batch:
                signal = alpha.compute(
                    prices.filter(pl.col("date") <= as_of_date),
                    fundamentals,
                    as_of_date,
                )
                all_signals.append(signal)

        # Parallel IC computation across horizons
        with ProcessPoolExecutor(max_workers=n_workers) as executor:
            futures = {
                executor.submit(self._compute_ic_for_horizon, signals, returns, h): h
                for h in [1, 2, 5, 10, 20, 60]
            }
            decay_results = {
                futures[f]: f.result() for f in as_completed(futures)
            }

        # ... aggregate results
```

### Performance Targets:
| Tier | Specification | Strategy |
|------|--------------|----------|
| Tier 1 | 3y/500 symbols <5min | Single-threaded, date-batching (252/batch) |
| Tier 2 | 5y/3000 symbols <5min | 4 workers, vectorized Polars, warm cache |
| Fallback | Memory-limited | Reduce batch_size to 126, use streaming |

---

## 9. Observability and Documentation (Addresses LOW Issue)

### Logging Contract:
```python
# All metrics functions include structured logging
class AlphaMetricsAdapter:
    def compute_ic(self, signal, returns, method="rank"):
        n_valid = self._count_valid(signal, returns)

        if n_valid < 30:
            logger.warning(
                "IC computation: insufficient data",
                extra={"n_valid": n_valid, "threshold": 30, "method": method}
            )
            return float("nan")

        coverage = n_valid / len(signal)
        if coverage < 0.5:
            logger.warning(
                "IC computation: low coverage",
                extra={"coverage": coverage, "threshold": 0.5, "n_valid": n_valid}
            )

        result = self._compute_ic_impl(signal, returns, method)
        logger.debug(
            "IC computed",
            extra={"ic": result, "method": method, "coverage": coverage}
        )
        return result
```

### Documentation Deliverables:
1. **`docs/CONCEPTS/alpha-research.md`**: Conceptual overview of alpha research
2. **Usage example in module docstring**: Complete working example
3. **Type hints**: Full type coverage for IDE support

### Example Usage (in `__init__.py` docstring):
```python
"""
Alpha Research Framework
========================

Example usage:

    from libs.alpha import PITBacktester, MomentumAlpha, AlphaMetricsAdapter
    from libs.data_quality.versioning import DatasetVersionManager

    # Initialize
    version_mgr = DatasetVersionManager(...)
    metrics = AlphaMetricsAdapter(prefer_qlib=True)
    backtester = PITBacktester(version_mgr, crsp, compustat, metrics)

    # Run backtest
    alpha = MomentumAlpha(lookback=252, skip=21)
    result = backtester.run_backtest(
        alpha=alpha,
        start_date=date(2020, 1, 1),
        end_date=date(2022, 12, 31),
        weight_method="zscore",
    )

    # Analyze results
    print(f"Mean IC: {result.mean_ic:.4f}")
    print(f"ICIR: {result.icir:.4f}")
    print(f"Average Turnover: {result.average_turnover:.2%}")
"""
```

---

## 10. Implementation Plan (Updated)

### Component 1: Alpha Definition Framework (Day 1)
**Files:** `libs/alpha/__init__.py`, `libs/alpha/alpha_definition.py`
- AlphaDefinition Protocol
- BaseAlpha class with utilities
- AlphaResult dataclass

### Component 2: Signal-to-Weight Converter (Day 1)
**Files:** `libs/alpha/portfolio.py`
- SignalToWeight class (zscore, quantile, rank methods)
- TurnoverCalculator class

### Component 3: Alpha Metrics Adapter (Day 1-2)
**Files:** `libs/alpha/metrics.py`
- AlphaMetricsAdapter with dual backend
- All metrics: IC, Rank IC, ICIR, Grouped IC, decay curve
- New metrics: autocorrelation, hit rate, coverage, long/short spread
- Qlib readiness check with proper logging

### Component 4: PIT Backtesting Engine (Day 2-3)
**Files:** `libs/alpha/research_platform.py`
- PITBacktester with strict PIT data contract
- BacktestResult with full metadata
- Parallel execution support

### Component 5: Alpha Library (Day 3)
**Files:** `libs/alpha/alpha_library.py`
- 5 canonical alphas: Momentum, Reversal, Value, Quality, Volatility

### Component 6: Analytics Extensions (Day 3-4)
**Files:** `libs/alpha/analytics.py`
- Decay curve analysis
- Grouped analysis (by GICS sector)

### Component 7: Test Suite (Day 4-5)
**Files:** `tests/libs/alpha/test_*.py`
- Unit tests for all metrics
- Contract tests for dual-backend parity
- Integration tests for PIT correctness
- Golden fixture tests

---

## 11. Acceptance Criteria Checklist (Updated)

### Core Requirements:
- [ ] Alpha signal definition framework with Protocol
- [ ] **Point-in-time backtesting engine with strict PIT data contract**
- [ ] IC and ICIR analysis with statistical significance
- [ ] Qlib metrics adapter with proper readiness check
- [ ] **Grouped IC (per GICS sector) with tolerance tests**
- [ ] Rank IC computation
- [ ] Local fallback when Qlib unavailable
- [ ] **Parity tests for ALL metrics (IC, ICIR, grouped IC, decay)**
- [ ] Alpha decay curve analysis

### New Metrics:
- [ ] Signal Autocorrelation (lag-1, lag-5, lag-20)
- [ ] Hit Rate / Positive Rate
- [ ] Coverage %
- [ ] Long/Short Spread (top decile - bottom decile)

### **Turnover (NEW - addresses HIGH issue):**
- [ ] SignalToWeight converter (zscore, quantile, rank methods)
- [ ] TurnoverCalculator with daily/average turnover
- [ ] Turnover included in BacktestResult

### Performance:
- [ ] Tier 1: 3 years / 500 symbols in <5 minutes (4-core/16GB)
- [ ] Tier 2: 5 years / 3000 symbols in <5 minutes (8-core/32GB, warm cache)
- [ ] **Parallel execution support with configurable workers**

### Validation:
- [ ] Contract tests parametrized over backends (extended to all metrics)
- [ ] Golden fixture tests with per-metric tolerances
- [ ] PIT validation tests (T vs T-1 delta)
- [ ] **PIT enforcement tests (verify no live provider access)**
- [ ] **Forward return overflow test (assert MissingForwardReturnError raised)**
- [ ] >90% test coverage

### **Observability (NEW - addresses LOW issue):**
- [ ] Structured logging for NaN/coverage warnings
- [ ] Usage example in module docstring
- [ ] `docs/CONCEPTS/alpha-research.md` documentation

---

## 12. File List

### Create:
- `libs/alpha/__init__.py`
- `libs/alpha/alpha_definition.py`
- `libs/alpha/alpha_library.py`
- `libs/alpha/metrics.py`
- `libs/alpha/research_platform.py`
- `libs/alpha/analytics.py`
- `libs/alpha/portfolio.py`
- `libs/alpha/exceptions.py` *(NEW - fail-fast exceptions)*
- `tests/libs/alpha/__init__.py`
- `tests/libs/alpha/test_alpha_definition.py`
- `tests/libs/alpha/test_metrics.py`
- `tests/libs/alpha/test_metrics_contract.py`
- `tests/libs/alpha/test_research_platform.py`
- `tests/libs/alpha/test_portfolio.py`
- `tests/libs/alpha/test_pit_enforcement.py` *(NEW - PIT/forward return tests)*
- `tests/fixtures/alpha_metrics_golden.parquet`
- `docs/CONCEPTS/alpha-research.md`

### Modify:
- None (new module)

---

## 13. Risks and Mitigations (Updated)

| Risk | Impact | Mitigation |
|------|--------|------------|
| Qlib API changes | Medium | Local fallback for ALL metrics with parity tests |
| Performance bottleneck | High | Parallel execution, date-batching, vectorized Polars |
| PIT data unavailable | High | Strict snapshot locking; raise PITViolationError (fail-fast) |
| **Metric parity divergence** | **Medium** | **Trust Qlib initially; log divergence; file issue for investigation** |
| **Forward return leakage** | **Critical** | **Strict snapshot cutoff; raise MissingForwardReturnError (fail-fast)** |

---

## 14. Review Questions Resolved

1. **GICS vs FF48?** → GICS (matches Factor Builder)
2. **Decay curve horizons?** → Fixed [1, 2, 5, 10, 20, 60] days
3. **Turnover portfolio weights?** → Configurable: zscore (default), quantile, rank
