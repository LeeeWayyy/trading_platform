# T6.4: Strategy Comparison Tool + Risk Dashboard DB Integration

## Implementation Plan

**Task:** T6.4 from P4T3_TASK.md
**Branch:** `feature/P4T3-T6.4-strategy-comparison`
**Effort:** 3-4 days
**Dependencies:** T6.1a (Auth/RBAC Core), T6.2 (Performance Dashboard), T6.3 (Risk Dashboard)

---

## Review History

| Version | Date | Reviewer | Status | Changes |
|---------|------|----------|--------|---------|
| v1.0 | 2025-12-13 | - | Initial | Initial plan |
| v1.1 | 2025-12-13 | Gemini | APPROVED | Implementation notes noted |
| v1.1 | 2025-12-13 | Codex | FIX REQUIRED | 3 MEDIUM, 3 LOW issues |
| v1.2 | 2025-12-13 | Gemini | APPROVED | No issues |
| v1.2 | 2025-12-13 | Codex | FIX REQUIRED | 2 MEDIUM, 1 LOW (event loop, Redis config, negative tests) |
| v1.3 | 2025-12-13 | Gemini | FIX REQUIRED | CRITICAL: async pool loop binding |
| v1.3 | 2025-12-13 | Codex | FIX REQUIRED | MEDIUM: async pool, LOW: run_async bridge, weight validation, test fixtures |
| v1.4 | 2025-12-13 | - | Revised | Fresh connection adapter pattern, run_async bridging, weight validation, test fixtures |

---

## Executive Summary

This task has two parts:
1. **T6.4a:** Wire real DB connections to the Risk Dashboard (fix `db_pool=None` issue)
2. **T6.4b:** Implement Strategy Comparison Tool with side-by-side metrics, correlation analysis, and rolling performance comparison

---

## T6.4a: Wire Real DB Connections to Risk Dashboard

### Problem Statement

The Risk Dashboard (`apps/web_console/pages/risk.py:65`) currently passes `db_pool=None` and `redis_client=None` to `StrategyScopedDataAccess`:

```python
# Current (broken):
scoped_access = StrategyScopedDataAccess(db_pool=None, redis_client=None, user=dict(user))
```

This causes `RiskService` to return placeholder/demo data instead of real portfolio risk metrics.

### Root Cause Analysis

1. `app.py` has `_get_db_pool()` decorated with `@st.cache_resource` that creates a psycopg3 async pool
2. `admin_users.py` correctly uses `_get_db_pool()` when rendering the page
3. `risk.py` does NOT import or use `_get_db_pool()` - it passes `None`

### Solution Design

**Approach 1 (Recommended): Import from app.py**
- Import `_get_db_pool` from `apps.web_console.app`
- Pass the real pool to `StrategyScopedDataAccess`
- Note: Since `_get_db_pool` returns an `AsyncConnectionPool`, the existing `acquire_connection` helper handles it correctly

**Approach 2: Create shared utility module**
- Move `_get_db_pool` to a shared module like `apps/web_console/utils/db_pool.py`
- Import from this shared module in both `app.py` and `risk.py`
- More modular but requires more changes

**Decision:** Use Approach 2 for better modularity and avoid circular imports. The `_get_db_pool` function currently lives in `app.py` alongside UI code, which isn't ideal for importing into page modules.

### Async/Sync Compatibility Analysis & Event Loop Strategy

**[FIXED v1.4 - Gemini CRITICAL + Codex MEDIUM: Async pool event-loop binding]**

**Problem:** psycopg3 `AsyncConnectionPool` binds to the event loop when first opened. The `run_async()` helper creates a fresh event loop per call via ThreadPoolExecutor. A cached pool will fail on the second call with loop-mismatch errors.

**Evidence:** The existing `app.py` pattern (lines 737-746) catches `RuntimeError` and falls back to sync connections - confirming the pooled approach fails silently.

**Solution: Fresh Connection Adapter Pattern**

Instead of caching an `AsyncConnectionPool` (which has loop-binding issues), we cache a lightweight **connection adapter** that creates fresh connections per call:

```python
# apps/web_console/utils/db_pool.py

from contextlib import asynccontextmanager
from collections.abc import AsyncIterator
from typing import Any

class AsyncConnectionAdapter:
    """Adapter providing fresh async connections per call.

    This adapter is safe to cache with @st.cache_resource because it only
    holds configuration (DATABASE_URL), not an actual pool. Each call to
    connection() creates a fresh psycopg.AsyncConnection bound to the
    current event loop, avoiding loop-binding issues with run_async().
    """

    def __init__(self, database_url: str, connect_timeout: float = 5.0):
        self._database_url = database_url
        self._connect_timeout = connect_timeout

    @asynccontextmanager
    async def connection(self) -> AsyncIterator[Any]:
        """Create a fresh async connection for each request.

        The connection is created and closed within the same event loop
        context, ensuring compatibility with run_async().
        """
        import psycopg
        async with await psycopg.AsyncConnection.connect(
            self._database_url,
            connect_timeout=self._connect_timeout,
        ) as conn:
            yield conn

@st.cache_resource
def get_db_pool() -> AsyncConnectionAdapter | None:
    """Get DB connection adapter (cacheable config, fresh connections per call).

    Returns:
        AsyncConnectionAdapter that creates fresh connections, or None if
        DATABASE_URL is not configured.
    """
    try:
        return AsyncConnectionAdapter(
            config.DATABASE_URL,
            connect_timeout=config.DATABASE_CONNECT_TIMEOUT,
        )
    except Exception:
        logger.exception("db_adapter_init_failed")
        return None
```

**Why this works:**
1. `AsyncConnectionAdapter` is just configuration - no event loop binding at creation
2. Each `run_async()` call creates a fresh event loop in ThreadPoolExecutor
3. `adapter.connection()` creates a fresh `psycopg.AsyncConnection` in that loop
4. Connection is used and closed within same async context
5. Compatible with `acquire_connection()` helper (has `.connection()` returning async CM)

**Trade-off:** No connection pooling benefits (each request creates new connection). For MVP this is acceptable; production optimization can add per-thread pooling later.

**Backward Compatibility:** The adapter implements the same interface as `AsyncConnectionPool` (`.connection()` returning async context manager), so `acquire_connection()` works unchanged.

### Implementation Steps (T6.4a)

1. **Create shared db_pool utility** (`apps/web_console/utils/db_pool.py`):
   - Move `_get_db_pool()` from `app.py` to new file
   - Export as `get_db_pool()` (drop leading underscore for public API)
   - **IMPORTANT:** Preserve `@st.cache_resource` decorator for connection pooling efficiency
   - Add `get_redis_client()` for optional Redis caching

2. **Redis Client Cache Isolation** (FIXED v1.3 - Codex MEDIUM: config source unspecified):

   **Implementation:**
   ```python
   @st.cache_resource
   def get_redis_client() -> "redis.asyncio.Redis | None":
       """Get async Redis client for strategy cache (DB=3).

       Configuration Source: REDIS_URL environment variable (same as sessions)
       with DB index overridden to 3 for cache isolation.
       """
       import os
       import redis.asyncio as redis_asyncio

       redis_url = os.getenv("REDIS_URL")
       if not redis_url:
           logger.warning("REDIS_URL not configured, caching disabled")
           return None

       # Parse URL and override DB to 3 for cache isolation
       # This preserves TLS/auth from the original URL
       cache_db = int(os.getenv("REDIS_STRATEGY_CACHE_DB", "3"))
       return redis_asyncio.Redis.from_url(redis_url, db=cache_db)
   ```

   **Key points:**
   - Source config: `REDIS_URL` environment variable (same as session store)
   - DB override: Uses `REDIS_STRATEGY_CACHE_DB` (default=3) for isolation
   - TLS/auth: Preserved from original URL via `from_url()` parsing
   - Type: Returns `redis.asyncio.Redis` (NOT sync) - required by `StrategyScopedDataAccess`
   - Fallback: Returns `None` if REDIS_URL not set → caching disabled gracefully

3. **Update `app.py`**:
   - Import `get_db_pool` from `utils.db_pool`
   - Remove local `_get_db_pool()` definition
   - Keep existing usage unchanged

4. **Update `risk.py`**:
   - Import `get_db_pool`, `get_redis_client` from `utils.db_pool`
   - Pass real connections to `StrategyScopedDataAccess`:
   ```python
   scoped_access = StrategyScopedDataAccess(
       db_pool=get_db_pool(),
       redis_client=get_redis_client(),  # Async client, DB=3, encrypted cache
       user=dict(user)
   )
   ```

5. **NOTE: performance.py is OUT OF SCOPE** (Codex LOW):
   - `performance.py` fetches data via HTTP APIs (not direct DB)
   - Its `StrategyScopedDataAccess` instantiation is a pattern placeholder
   - Changing it would break existing HTTP-based data flow
   - Will NOT modify performance.py in this task

6. **Add tests with real DB fixtures AND negative-path tests** (FIXED v1.3 - Codex LOW):
   - Unit test for `get_db_pool()` and `get_redis_client()` (mock)
   - **Integration test with real DB fixtures for risk dashboard**
   - Test file: `tests/apps/web_console/integration/test_risk_dashboard_db.py`
   - Fixtures: Use pytest-asyncio + test database with sample pnl_daily data

   **Negative-path tests (graceful fallback verification):**
   ```python
   # tests/apps/web_console/utils/test_db_pool.py

   def test_get_db_pool_returns_none_when_db_unavailable(monkeypatch):
       """Pool returns None when DATABASE_URL invalid → risk.py shows placeholder."""
       monkeypatch.setenv("DATABASE_URL", "postgresql://invalid:5432/db")
       pool = get_db_pool()
       # Pool creation may succeed but connection will fail
       # RiskService handles this gracefully via try/except

   def test_get_redis_client_returns_none_when_url_missing(monkeypatch):
       """Redis client returns None when REDIS_URL not set → caching disabled."""
       monkeypatch.delenv("REDIS_URL", raising=False)
       client = get_redis_client()
       assert client is None

   def test_risk_dashboard_renders_placeholder_when_db_none():
       """Risk dashboard shows placeholder data when db_pool=None."""
       # Verify RiskService returns is_placeholder=True, placeholder_reason set
       # Verify UI renders the demo data warning prominently

   def test_cache_disabled_when_encryption_key_absent(monkeypatch):
       """StrategyScopedDataAccess disables cache without STRATEGY_CACHE_ENCRYPTION_KEY."""
       monkeypatch.delenv("STRATEGY_CACHE_ENCRYPTION_KEY", raising=False)
       # Verify _cipher is None, cache operations are skipped
   ```

### Files Changed (T6.4a)

| File | Action | Description |
|------|--------|-------------|
| `apps/web_console/utils/db_pool.py` | CREATE | Shared DB pool utility with `get_db_pool()` and `get_redis_client()` (async, DB=3) |
| `apps/web_console/app.py` | MODIFY | Import from `utils.db_pool` instead of local definition |
| `apps/web_console/pages/risk.py` | MODIFY | Wire real DB connections |
| `tests/apps/web_console/utils/test_db_pool.py` | CREATE | Unit tests for db_pool utility |
| `tests/apps/web_console/integration/test_risk_dashboard_db.py` | CREATE | Integration tests with real DB fixtures |

---

## T6.4b: Strategy Comparison Tool

### Requirements (from P4T3_TASK.md)

1. **Side-by-side strategy metrics** (authorized strategies only)
2. **Correlation analysis** between strategies
3. **Rolling performance comparison**
4. **Combined portfolio simulation**

### Solution Design

#### Page Structure (`pages/compare.py`)

```
┌─────────────────────────────────────────────────────────────────┐
│  Strategy Comparison Tool                                        │
├─────────────────────────────────────────────────────────────────┤
│  [Strategy Selector] Select 2-4 strategies to compare           │
│                                                                 │
│  ┌───────────────────────────────────────────────────────────┐ │
│  │ Side-by-Side Metrics Table                                │ │
│  │ ┌─────────┬───────────┬───────────┬───────────┐          │ │
│  │ │ Metric  │ Strategy1 │ Strategy2 │ Strategy3 │          │ │
│  │ ├─────────┼───────────┼───────────┼───────────┤          │ │
│  │ │ Total   │ 12.5%     │ 8.2%      │ 15.1%     │          │ │
│  │ │ Return  │           │           │           │          │ │
│  │ ├─────────┼───────────┼───────────┼───────────┤          │ │
│  │ │ Sharpe  │ 1.2       │ 0.9       │ 1.5       │          │ │
│  │ └─────────┴───────────┴───────────┴───────────┘          │ │
│  └───────────────────────────────────────────────────────────┘ │
│                                                                 │
│  ┌───────────────────────────────────────────────────────────┐ │
│  │ Rolling Performance Comparison (Line Chart)               │ │
│  │ [Equity curves overlaid for selected strategies]          │ │
│  └───────────────────────────────────────────────────────────┘ │
│                                                                 │
│  ┌───────────────────────────────────────────────────────────┐ │
│  │ Correlation Matrix (Heatmap)                              │ │
│  │ Shows return correlation between selected strategies      │ │
│  └───────────────────────────────────────────────────────────┘ │
│                                                                 │
│  ┌───────────────────────────────────────────────────────────┐ │
│  │ Combined Portfolio Simulation                             │ │
│  │ Weight sliders + simulated combined performance           │ │
│  └───────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
```

#### Data Flow

```
User selects strategies
    │
    ▼
StrategyScopedDataAccess.get_pnl_summary(strategies)
    │
    ▼
ComparisonService computes:
    ├── Side-by-side metrics (total return, sharpe, max DD, etc.)
    ├── Rolling cumulative returns (equity curves)
    ├── Correlation matrix (pairwise correlations)
    └── Combined portfolio simulation (weighted average)
    │
    ▼
Components render charts/tables
```

#### Components

1. **`components/comparison_charts.py`**:
   - `render_equity_comparison(strategies_data)`: Overlaid equity curves
   - `render_metrics_comparison_table(metrics)`: Side-by-side metrics table
   - `render_combined_portfolio(weights, data)`: Portfolio weight sliders + combined equity

2. **`components/correlation_matrix.py`**:
   - `render_correlation_heatmap(correlation_df)`: Heatmap visualization
   - Uses `plotly` for interactive heatmap

3. **`services/comparison_service.py`**:
   - `ComparisonService`: Business logic for computing comparison metrics
   - Uses `StrategyScopedDataAccess` for data fetching (RBAC-enforced)

### Implementation Steps (T6.4b)

1. **Create `services/comparison_service.py`**:
   - `ComparisonService` class with methods:
     - `async get_comparison_data(strategy_ids, date_from, date_to)` -> dict
     - `compute_correlation_matrix(pnl_data)` -> DataFrame (sync, pure computation)
     - `compute_combined_portfolio(weights, pnl_data)` -> dict (sync, pure computation)
   - Uses `StrategyScopedDataAccess` (RBAC-enforced)
   - **[FIXED v1.4 - Codex LOW: run_async bridging]** All async DB calls via `run_async()`:
     ```python
     # pages/compare.py usage pattern
     from apps.web_console.utils.async_helpers import run_async

     comparison_service = ComparisonService(scoped_access)
     data = run_async(
         comparison_service.get_comparison_data(strategy_ids, date_from, date_to),
         timeout=30,
     )
     ```

2. **Create `components/comparison_charts.py`**:
   - `render_equity_comparison(data)` - overlaid line chart
   - `render_metrics_table(metrics)` - styled dataframe
   - `render_portfolio_simulator(strategies, default_weights)` - sliders + preview

3. **Create `components/correlation_matrix.py`**:
   - `render_correlation_heatmap(corr_matrix)` - plotly heatmap
   - Color coding: green (positive), red (negative), white (neutral)

4. **Create `pages/compare.py`**:
   - Strategy multi-select (2-4 strategies, RBAC-filtered)
   - Date range selector (reuse from performance.py)
   - Call components to render dashboard sections
   - Use `@require_auth` and permission check (`VIEW_PNL`)
   - **EXPLICIT FEATURE FLAG GATING** (Codex LOW):
     ```python
     if not FEATURE_STRATEGY_COMPARISON:
         st.info("Strategy Comparison is not currently enabled.")
         st.stop()
     ```

5. **Navigation approach** (Codex LOW - alignment with Streamlit pages pattern):
   - The compare page lives at `apps/web_console/pages/compare.py`
   - Streamlit multi-page apps auto-discover pages in the `pages/` directory
   - **No sidebar modification needed in `app.py`** - Streamlit handles this
   - Alternative: If using manual navigation (like `app.py` does), add to sidebar ONLY if FEATURE_STRATEGY_COMPARISON is enabled:
     ```python
     pages = ["Dashboard", "Manual Order Entry", "Kill Switch", "Audit Log"]
     if FEATURE_STRATEGY_COMPARISON:
         pages.append("Strategy Comparison")
     ```

6. **Create tests**:
   - Unit tests for `ComparisonService`
   - Component tests with mock data
   - Integration test for page with auth

7. **Create documentation**:
   - `docs/CONCEPTS/strategy-comparison.md`

### Files to Create (T6.4b)

| File | Description |
|------|-------------|
| `apps/web_console/services/comparison_service.py` | Comparison business logic |
| `apps/web_console/components/comparison_charts.py` | Equity comparison + metrics table |
| `apps/web_console/components/correlation_matrix.py` | Correlation heatmap |
| `apps/web_console/pages/compare.py` | Strategy comparison page |
| `tests/apps/web_console/services/test_comparison_service.py` | Service unit tests |
| `tests/apps/web_console/test_strategy_comparison.py` | Integration tests |
| `docs/CONCEPTS/strategy-comparison.md` | User documentation |

### Files to Modify (T6.4b)

| File | Change |
|------|--------|
| `apps/web_console/app.py` | Add "Strategy Comparison" to sidebar navigation (conditionally, if FEATURE_STRATEGY_COMPARISON is enabled) |
| `apps/web_console/config.py` | Add `FEATURE_STRATEGY_COMPARISON` feature flag (default: false) |

---

## Security Considerations

1. **RBAC Enforcement**:
   - All data queries go through `StrategyScopedDataAccess`
   - Strategy selector only shows authorized strategies
   - `@require_auth` decorator on page entry point
   - Permission check: `has_permission(user, Permission.VIEW_PNL)`

2. **Data Isolation**:
   - Cache keys include `user_id` and strategy hash
   - No cross-user data leakage possible

3. **Input Validation**:
   - Date range validation (same as performance.py)
   - Strategy count validation (2-4 strategies)
   - **[FIXED v1.4 - Codex LOW: weight bounds]** Weight validation:
     - Each weight: `0.0 ≤ w ≤ 1.0` (no negative or >100% allocations)
     - Sum constraint: `abs(sum(weights) - 1.0) ≤ 0.001` (tolerance for float precision)
     - User feedback: Show error message if validation fails, prevent simulation
     ```python
     def validate_weights(weights: dict[str, float]) -> tuple[bool, str]:
         """Validate portfolio weights for combined simulation."""
         for strategy_id, w in weights.items():
             if w < 0.0 or w > 1.0:
                 return False, f"Weight for {strategy_id} must be between 0% and 100%"
         if abs(sum(weights.values()) - 1.0) > 0.001:
             return False, f"Weights must sum to 100% (currently {sum(weights.values())*100:.1f}%)"
         return True, ""
     ```

---

## Testing Strategy

**[FIXED v1.4 - Codex LOW: test fixtures and coverage clarity]**

### Test Fixtures

Fixtures are defined in `tests/conftest.py` and `tests/apps/web_console/conftest.py`:

```python
# tests/apps/web_console/conftest.py

@pytest.fixture
def mock_pnl_data() -> list[dict]:
    """Sample P&L data for 3 strategies over 30 days."""
    return [
        {"strategy_id": "alpha_baseline", "trade_date": date(2025, 1, i), "daily_pnl": 100 * (i % 5 - 2)}
        for i in range(1, 31)
    ] + [
        {"strategy_id": "momentum_v1", "trade_date": date(2025, 1, i), "daily_pnl": 150 * (i % 3 - 1)}
        for i in range(1, 31)
    ]

@pytest.fixture
def mock_scoped_access(mock_pnl_data):
    """Mock StrategyScopedDataAccess with canned data."""
    access = MagicMock(spec=StrategyScopedDataAccess)
    access.get_pnl_summary = AsyncMock(return_value=mock_pnl_data)
    access.authorized_strategies = ["alpha_baseline", "momentum_v1"]
    return access

@pytest.fixture
async def test_db_pool():
    """Real async connection adapter for integration tests.

    Uses TEST_DATABASE_URL env var (defaults to test DB).
    Seeds pnl_daily table with deterministic data.
    """
    # Setup: seed test data
    # Teardown: cleanup
```

### Unit Tests
- `ComparisonService` methods (correlation, combined portfolio, metrics)
- Component rendering with mock data
- Edge cases: empty data, single strategy, invalid weights
- Weight validation boundary tests (0, 1, negative, >1, sum != 1)

### Integration Tests
- Full page load with mock DB adapter
- RBAC filtering verification
- Cache key isolation
- **[NEW] Second-call verification**: Execute DB access twice to confirm fresh connection pattern works

### Security Tests
- Verify unauthorized strategy not accessible
- Verify cross-user cache isolation

### Coverage Target
- **Target: 85%** (realistic for new service code)
- Focus on business logic (`ComparisonService`, validation)
- UI components tested with snapshot/render tests (lower coverage acceptable)
- Integration tests prioritize critical paths over exhaustive coverage

---

## Estimated Effort Breakdown

| Component | Effort |
|-----------|--------|
| T6.4a: DB pool wiring | 0.5 days |
| T6.4b: ComparisonService | 0.5 days |
| T6.4b: Components | 1 day |
| T6.4b: Compare page | 0.5 days |
| T6.4b: Tests | 0.5-1 day |
| T6.4b: Documentation | 0.5 days |
| **Total** | **3-4 days** |

---

## Dependencies

- `pandas` (already in requirements)
- `plotly` (for heatmap - already used by existing components)
- `streamlit` (core framework)

No new dependencies required.

---

## Risks and Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Circular import with app.py | Medium | Low | Use shared utility module pattern |
| Performance with many strategies | Low | Medium | Limit to 4 strategies, cache results |
| Correlation matrix NaN values | Medium | Low | Handle edge cases (single data point) |

---

## Acceptance Criteria

### T6.4a
- [ ] Risk Dashboard loads real data (not placeholder) when DB available
- [ ] `get_db_pool()` returns psycopg3 AsyncConnectionPool with `@st.cache_resource`
- [ ] `get_redis_client()` returns `redis.asyncio.Redis` with DB=3 (separate cache)
- [ ] Graceful fallback when DB unavailable (existing behavior preserved)
- [ ] Integration tests with real DB fixtures pass
- [ ] Unit tests for db_pool utility pass

### T6.4b
- [ ] Strategy selector shows only authorized strategies (RBAC-enforced)
- [ ] Side-by-side metrics table renders correctly
- [ ] Correlation heatmap visualizes strategy correlations
- [ ] Rolling performance comparison shows overlaid equity curves
- [ ] Combined portfolio simulation with weight sliders
- [ ] Feature flag `FEATURE_STRATEGY_COMPARISON` gates page visibility (explicit check at page entry)
- [ ] Navigation conditionally added to sidebar based on feature flag
- [ ] Permission check `VIEW_PNL` enforced at page entry
- [ ] Tests pass with ≥85% coverage (service logic)
- [ ] Documentation created

---

**Plan Version:** 1.3
**Author:** Claude Code
**Date:** 2025-12-13
**Review Status:** Pending review
